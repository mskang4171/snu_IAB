{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PyTorch 1.0.0-3.6",
      "language": "python",
      "name": "multitask"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "RNN_practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ec1NCtLafD2"
      },
      "source": [
        "# 1. Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFpwJWt6H8i-"
      },
      "source": [
        "### 1-1. Import Libraries\n",
        "- 데이터셋 다운로드와 전처리를 쉽게 하는 torchtext 라이브러리를 import 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuWiZzTJIHlX"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data, datasets\n",
        "import random\n",
        "import time\n",
        "import spacy\n",
        "import numpy as np\n",
        "from torch import Tensor"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlBRh_erIV5Y"
      },
      "source": [
        "### 1-2. Load data\n",
        "- Field 를 정의합니다.\n",
        "- IMDB 데이터를 다운받습니다.\n",
        "- Train,valid,test 데이터셋으로 split 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qAjGhs_momr"
      },
      "source": [
        "TEXT = data.Field(tokenize = 'spacy', include_lengths=True)\n",
        "LABEL = data.LabelField(dtype = torch.float) "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAyLqGf_sOgf",
        "outputId": "0f1fecb1-14a0-4779-c8c7-ddf876afb647",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download IMDB data (about 3mins)\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:07<00:00, 10.8MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhhfnEZYsld1"
      },
      "source": [
        "# Set the random seed\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dDuDBdvsOmk"
      },
      "source": [
        "# Split train and valid data\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdLyvaV6o-TY",
        "outputId": "2282d243-2768-427f-c856-dab8785eba51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Number of training examples: {}'.format(len(train_data)))\n",
        "print('Number of validation examples: {}'.format(len(valid_data)))\n",
        "print('Number of testing examples: {}'.format(len(test_data)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IEhTw1Z5k3B",
        "outputId": "325a8fee-9fc7-46ef-a9c7-93787f17b1f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# print example\n",
        "print(vars(train_data.examples[0]))\n",
        "print(' '.join(vars(train_data.examples[0])['text']))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['You', 'know', 'what', 'you', 'are', 'getting', 'when', 'you', 'purchase', 'a', 'Hallmark', 'card', '.', 'A', 'sappy', ',', 'trite', 'verse', 'and', 'that', 'will', 'be', '$', '3.99', ',', 'thank', 'you', 'very', 'much', '.', 'You', 'get', 'the', 'same', 'with', 'a', 'Hallmark', 'movie', '.', 'Here', 'we', 'get', 'a', 'ninety', 'year', 'old', 'Ernie', 'Borgnine', 'coming', 'out', 'of', 'retirement', 'to', 'let', 'us', 'know', 'that', 'as', 'a', 'matter', 'of', 'fact', ',', 'he', 'is', 'not', 'dead', 'like', 'we', 'thought', '.', 'Poor', 'Ernie', ',', 'he', 'is', 'the', 'poor', 'soul', 'that', 'married', 'Ethel', 'Merman', 'several', 'years', 'ago', 'and', 'the', 'marriage', 'lasted', 'a', 'few', 'weeks', '.', 'In', 'this', 'flick', ',', 'Ernie', 'jumps', 'in', 'feet', 'first', 'and', 'portrays', 'the', 'Grandpa', 'that', 'bonds', 'with', 'his', 'long', 'lost', 'grandkid', '.', 'We', 'have', 'seen', 'it', 'before', '.', 'You', 'might', 'enjoy', 'this', 'movie', 'but', 'please', 'do', \"n't\", 'say', 'that', 'you', 'were', 'not', 'warned', '.'], 'label': 'neg'}\n",
            "You know what you are getting when you purchase a Hallmark card . A sappy , trite verse and that will be $ 3.99 , thank you very much . You get the same with a Hallmark movie . Here we get a ninety year old Ernie Borgnine coming out of retirement to let us know that as a matter of fact , he is not dead like we thought . Poor Ernie , he is the poor soul that married Ethel Merman several years ago and the marriage lasted a few weeks . In this flick , Ernie jumps in feet first and portrays the Grandpa that bonds with his long lost grandkid . We have seen it before . You might enjoy this movie but please do n't say that you were not warned .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEsf_UifafEH"
      },
      "source": [
        "### 1-3. Cuda Setup\n",
        "- GPU 사용을 위한 Cuda 설정\n",
        "- Colab 페이지 상단 메뉴>수정>노트설정에서 GPU 사용 설정이 선행되어야 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4BsnajZafEI",
        "outputId": "c9c0a7f1-584d-4f3f-a8d6-2802fcaa8264",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if USE_CUDA else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8fuDdBOafEO",
        "outputId": "0491b287-33b0-4ad0-edff-d47a68006b03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Nov 10 11:56:21 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    26W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC9xHrlt4LL9"
      },
      "source": [
        "##2. Preprocess data\n",
        "- Vocab (단어장) 을 만듭니다.\n",
        "- Iterator 를 만듭니다. (Iterator 를 통해 batch training 을 위한 batching 과 padding, 그리고 데이터 내 단어들의 인덱스 변환이 이루어집니다.)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snEZbJb4WBZS",
        "outputId": "a3401165-fa45-443e-d0e4-a24f45c0e466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load pre-trained word vectors (about 7mins)\n",
        "TEXT.build_vocab(train_data, vectors = \"glove.6B.100d\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                           \n",
            "100%|█████████▉| 399714/400000 [00:23<00:00, 17295.48it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fNOoZwZurdQ",
        "outputId": "52ef5f17-b11e-4c38-d0e8-4d4b0ce70e4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 101446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suJRz9fgur1_"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data,\n",
        "                 max_size = MAX_VOCAB_SIZE,\n",
        "                 vectors = \"glove.6B.100d\",\n",
        "                 unk_init = torch.Tensor.normal_                 \n",
        "                 )\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES2qQ9kdu71e",
        "outputId": "fddf2a13-1d7e-4775-a646-2299a72f94ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "692haI3q1XZm",
        "outputId": "3872f6ea-7b03-4c60-9d40-3781a17cbce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "TEXT.vocab.itos[:10]  #itos – A list of token strings indexed by their numerical identifiers."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TolmqsvNvoCD",
        "outputId": "b3d75cd3-a14c-458a-8514-bac2ea58dbb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_dict = TEXT.vocab.stoi # stoi – A collections.defaultdict instance mapping token strings to numerical identifiers.\n",
        "print(len(word_dict))\n",
        "print(word_dict['<unk>'], word_dict['<pad>'])\n",
        "print(list(word_dict)[-1], word_dict[list(word_dict)[-1]])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25002\n",
            "0 1\n",
            "buffaloes 25001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUCn66DV3EQS",
        "outputId": "bc802e70-436f-46a5-9fe4-65514f580dd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(TEXT.vocab.vectors.shape)\n",
        "print(TEXT.vocab.vectors)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n",
            "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
            "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [-0.3556, -0.2554, -0.1192,  ..., -0.1305,  0.1196, -0.4377],\n",
            "        [-0.5618,  0.5658, -0.2214,  ..., -0.2283,  0.4419,  0.5798],\n",
            "        [ 0.3757,  0.3498,  0.7955,  ...,  0.7336,  0.2335, -0.1470]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvmmOAIPJTA5",
        "outputId": "ae6ed6d1-a8b7-427c-cbc4-6356019947ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Batching - construct iterator\n",
        "BATCH_SIZE = 32   \n",
        "\n",
        "train_iterator = data.Iterator(\n",
        "    train_data, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)\n",
        "\n",
        "# shape: BATCH_SIZE x maximum length of sentence \n",
        "\n",
        "for batch in train_iterator:\n",
        "    break\n",
        "print(batch.text)\n",
        "print(len(batch.text[0]))\n",
        "print(batch.label)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[   66,  2644,  2739,  ...,   421,    66,    66],\n",
            "        [  671,    39, 14358,  ...,   752,     9,   293],\n",
            "        [   97,   976,    10,  ...,   960,  1053,    10],\n",
            "        ...,\n",
            "        [    1,     1,     1,  ...,     1,     1,     1],\n",
            "        [    1,     1,     1,  ...,     1,     1,     1],\n",
            "        [    1,     1,     1,  ...,     1,     1,     1]], device='cuda:0'), tensor([187, 171, 173, 239, 253, 157, 161, 367, 130, 128, 239, 301, 287, 617,\n",
            "        570, 347, 261, 384, 147, 181, 164, 159, 188, 230,  64, 176, 260, 592,\n",
            "        342, 187, 233, 332], device='cuda:0'))\n",
            "617\n",
            "tensor([0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uKU20YTxgaQ",
        "outputId": "75847b70-6651-4ac4-f4f5-719dd9efc427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# BucketIterator\n",
        "\n",
        "train_iterator = data.BucketIterator(\n",
        "    train_data, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)\n",
        "\n",
        "for batch in train_iterator:\n",
        "    break\n",
        "print(batch.text)\n",
        "print(len(batch.text[0]))\n",
        "print(batch.label)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[   25,    66,    66,  ...,    27,    66,    11],\n",
            "        [   22,    24,    24,  ...,     0,   426,   158],\n",
            "        [   19,     9,     9,  ...,    18,  1789,   124],\n",
            "        ...,\n",
            "        [  807, 23936,  3698,  ...,     0,    67,     4],\n",
            "        [  711,   117,    24,  ...,     1,     1,     1],\n",
            "        [    4,     4,     4,  ...,     1,     1,     1]], device='cuda:0'), tensor([133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,\n",
            "        132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 131, 131, 131,\n",
            "        131, 131, 131, 131], device='cuda:0'))\n",
            "133\n",
            "tensor([0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
            "        0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOD6AiIwKu-G"
      },
      "source": [
        "# Batching - construct iterator\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_sizes = (BATCH_SIZE, BATCH_SIZE, BATCH_SIZE),\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_tAoIcUMp3v"
      },
      "source": [
        "##3. Build Model\n",
        "- Embedding layer, RNN layer, Dropout layer, Fully-connected layer 로 이루어진 모델을 만듭니다.\n",
        "- 미리 학습된 워드 임베딩을 임베딩 레이어에 올립니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jdh8JGOMyYq"
      },
      "source": [
        "class Model(nn.Module):  # Custom model 정의 \n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define parameters\n",
        "        self.hidden_him = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Define Layers\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        # RNN layer\n",
        "        # self.rnn = nn.RNN(embedding_dim, hidden_dim, n_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        # self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "\n",
        "        # Fully connected layer\n",
        "        #self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim) # hidden_dim *2 인 이유? bidirectional이기 때문\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        # text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        # embedded = [batch size, sent len, emb dim] if batch_first = True\n",
        "        \n",
        "        # output, hidden = self.rnn(embedded)\n",
        "        # output, (hidden, cell) = self.lstm(embedded)\n",
        "        output, hidden = self.gru(embedded)\n",
        "\n",
        "\n",
        "        # hidden = [num_layers x num_directions, batch_size, hidden_size]\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "\n",
        "        return self.fc(hidden.squeeze(0))\n"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz7u51ACdAF1"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## (추가설명)\n",
        "### Bidirectional RNN 의 \"concatenation\" 에 대하여\n",
        "* `batch_size = 3, hidden_dim = 10, n_layers = 1, bidirectional = True` 일때 \n",
        "* RNN 모델은 forward layer 와 backward layer 총 2개 레이어를 가지게 됩니다.\n",
        "* 편의상 forward layer 의 hidden state 의 모든 unit 이 0이 되고,\n",
        "backward layer 의 경우 모두 1이 된다고 가정하겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWfDw4SrpPuh",
        "outputId": "dc7fd876-7b6c-4b52-fe78-9b68cf08edbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 한개의 input 이 들어왔을때, 마지막 타임 스텝에서의 forward/backward hidden state 는 각각 다음과 같은 형태가 될 것입니다.\n",
        "h_forward = torch.zeros(1,10) \n",
        "h_backward = torch.ones(1,10)\n",
        "print(h_forward)\n",
        "print(h_backward)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-qmnArWg59T"
      },
      "source": [
        " \n",
        "\n",
        "\n",
        "*   Torch.nn 제공 RNN 모듈은 2개의 아웃풋 중 하나로 hidden state 을 출력하며,\n",
        "> `output, hidden = self.rnn(embedded)`\n",
        "*   `hidden`은 모델에 들어있는 **모든 레이어**의 last hidden state 을 출력합니다.\n",
        "*   따라서 `hidden` 의 형태는 `[num_layers x num_directions, batch_size, hidden_size]`가 됩니다.\n",
        "\n",
        "* 모델에서 총 n개의 layer 를 사용할 경우, 순서대로 _1번째 forward, 1번째 backward, 2번째 forward, 2번째 backward, ..., n번째 forward, n번째 backward_ 가 표시됩니다.\n",
        "* 이 예제에서는 `n_layers = 1`이므로 `hidden` 의 shape 은 `[2,3,10]` 이 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1WG9R_AD5j5",
        "outputId": "2f46e0ca-1f30-47e2-f9aa-c95bfb6863f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# hidden 은 아래와 같이 생기게 됩니다.\n",
        "hidden = torch.cat([h_forward.unsqueeze(0).repeat([1,3,1]),h_backward.unsqueeze(0).repeat([1,3,1])])\n",
        "\n",
        "print(hidden)\n",
        "print(hidden.shape)"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
            "torch.Size([2, 3, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8l5cPHpk4k0"
      },
      "source": [
        "\n",
        "*   우리는 forward 와 backward layer 각각에서 나온 last hidden state를 나란히 합치고자 합니다.\n",
        "*  `hidden[-2,:,:]` 는 forward layer 의 last hidden state 을 나타내고\n",
        "*  `hidden[-1,:,:]` 는 backward layer 의 last hidden state 을 나타냅니다.\n",
        "* 이 두개를 hidden_size 를 나타내는 dimension=1 의 방향으로 concatenate 합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4zx6Cj_bNoC",
        "outputId": "db43f2a5-d45d-4068-efff-b8d661a7546f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 최종적으로 사용하는 Bidirectional RNN 모델의 아웃풋은 다음과 같은 형태를 가집니다.\n",
        "h_concat = torch.cat([hidden[-2,:,:],hidden[-1,:,:]],dim=1)\n",
        "print(h_concat)\n",
        "print(h_concat.shape)"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1.]])\n",
            "torch.Size([3, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrXn7s7dtDd8"
      },
      "source": [
        "## (추가설명 종료)\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4EffzRaafEY"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "# HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "# N_LAYERS = 1\n",
        "# N_LAYERS = 3\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = Model(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)    # Make model instance\n"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCUKXn94afEf",
        "outputId": "4a7a7354-b312-4a1f-8f8c-d29b4b5b8595",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)  # Count number of elements of all parameters\n",
        "\n",
        "print('The model has {:,} trainable parameters'.format(count_parameters(model)))"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 4,233,321 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgZ8wIYlG-_C",
        "outputId": "f9aa5028-9bde-4536-f5dd-9e42216c5437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load pretrained embeddings\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "print(type(pretrained_embeddings))\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings);"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDy-PGhSQcTd"
      },
      "source": [
        "## 4. Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09bHscfRG9ju"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())   # Gradient Descent 실행"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeZZ33ZeafEt"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()  # 손실함수 정의 "
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bOa8C1tafEz"
      },
      "source": [
        "model = model.to(device)  #모델을 GPU 로 이동\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7exIxGaZafE4"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Eb16jU0afFA"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()  # Gradient 0으로 초기화\n",
        "                \n",
        "        predictions = model(batch.text[0]).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()    # backward pass (gradient 계산)\n",
        "        \n",
        "        optimizer.step()   # parameter update\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8da_fbPRQ9I3"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text[0]).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZhS9Q2fSLyr"
      },
      "source": [
        "### *Do Training!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uUWlVrUQ-lz",
        "outputId": "26259617-d551-4fb8-d9ab-ca38fa8dfe10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'rnn-model.pt')\n",
        "    \n",
        "    print('Epoch: {:02}'.format(epoch+1))\n",
        "    print('\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%'.format(train_loss, train_acc*100))\n",
        "    print('\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%'.format(valid_loss, valid_acc*100))"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 0.529 | Train Acc: 70.77%\n",
            "\t Val. Loss: 0.399 |  Val. Acc: 83.57%\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.244 | Train Acc: 90.44%\n",
            "\t Val. Loss: 0.335 |  Val. Acc: 85.94%\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.144 | Train Acc: 94.93%\n",
            "\t Val. Loss: 0.308 |  Val. Acc: 88.69%\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.077 | Train Acc: 97.48%\n",
            "\t Val. Loss: 0.331 |  Val. Acc: 89.11%\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.034 | Train Acc: 98.96%\n",
            "\t Val. Loss: 0.435 |  Val. Acc: 88.46%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mXZ46wgRHWR",
        "outputId": "e093415b-d22b-4856-98d3-f47661c6a8e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.load_state_dict(torch.load('rnn-model.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print('Test Loss: {:.3f} | Test Acc: {:.2f}%'.format(test_loss, test_acc*100))"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.312 | Test Acc: 88.59%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EtTQaIdafFL"
      },
      "source": [
        "## 5. Test model\n",
        "우리가 직접 예문을 작성해서 트레인된 모델에서 예문을 어떻게 평가하는지 확인합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hxev65tafFQ"
      },
      "source": [
        "# 토크나이저로 spacy 를 사용합니다.\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "# 사용자가 입력한 sentence 를 훈련된 모델에 넣었을때의 결과값을 확인합니다.\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  # Tokenization\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]   # 위에서 만든 vocab 에 부여된 index 로 indexing\n",
        "    tensor = torch.LongTensor(indexed).to(device)   # indexing 된 sequence 를 torch tensor 형태로 만들어줌.\n",
        "    tensor = tensor.unsqueeze(1)   # 입력 텐서에 batch 차원을 만들어줌.\n",
        "    prediction = torch.sigmoid(model(tensor))  # 모델에 입력한 후 확률값 도출을 위한 sigmoid 적용 \n",
        "    return prediction.item() # prediction 값 출력"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIk_EjmoSFdU",
        "outputId": "9cf17846-b2f9-49f4-9b32-081fa7a145ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model, \"This film is terrible\") #아주 낮은 값의 확률이 도출되는 것을 확인할 수 있습니다.(부정)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0011325414525344968"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1ZZJbxaSFaa",
        "outputId": "41c229fd-9451-414b-adc3-3ed0cc82baec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model, \"This film is great\") #아주 높은 값의 확률이 도출되는 것을 확인할 수 있습니다. (긍정)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9992702603340149"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    }
  ]
}
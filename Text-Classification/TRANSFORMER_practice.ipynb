{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PyTorch 1.0.0-3.6",
      "language": "python",
      "name": "multitask"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "TRANSFORMER_practice_HW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ec1NCtLafD2"
      },
      "source": [
        "# 1. Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFpwJWt6H8i-"
      },
      "source": [
        "### 1-1. Import Libraries\n",
        "- 데이터셋 다운로드와 전처리를 쉽게 하는 torchtext 라이브러리를 import 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuWiZzTJIHlX"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data, datasets\n",
        "import random\n",
        "import time\n",
        "import spacy\n",
        "import numpy as np\n",
        "from torch import Tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlBRh_erIV5Y"
      },
      "source": [
        "### 1-2. Load data\n",
        "- Field 를 정의합니다.\n",
        "- IMDB 데이터를 다운받습니다.\n",
        "- Train,valid,test 데이터셋으로 split 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qAjGhs_momr"
      },
      "source": [
        "TEXT = data.Field(tokenize = 'spacy', include_lengths= True)\n",
        "## HW ##\n",
        "# 가변 길이가 아닌 고정된 길이의 seqeunce 로 데이터를 입력받을 수 있도록\n",
        "# Data field 를 다시 initialize 해주자\n",
        "\n",
        "# MAX_LEN = 10\n",
        "# MAX_LEN = 20\n",
        "# MAX_LEN = 30\n",
        "\n",
        "# TEXT = data.Field(tokenize = 'spacy', fix_length = MAX_LEN)\n",
        "\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAyLqGf_sOgf",
        "outputId": "9e6559dd-d4af-425b-8425-204643160e98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download IMDB data (about 3mins)\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:07<00:00, 11.1MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhhfnEZYsld1"
      },
      "source": [
        "# Set the random seed\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dDuDBdvsOmk"
      },
      "source": [
        "# Split train and valid data\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdLyvaV6o-TY",
        "outputId": "4ce89d5a-04b2-469d-bb88-87bd75cbe5ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Number of training examples: {}'.format(len(train_data)))\n",
        "print('Number of validation examples: {}'.format(len(valid_data)))\n",
        "print('Number of testing examples: {}'.format(len(test_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEsf_UifafEH"
      },
      "source": [
        "### 1-3. Cuda Setup\n",
        "- GPU 사용을 위한 Cuda 설정\n",
        "- Colab 페이지 상단 메뉴>수정>노트설정에서 GPU 사용 설정이 선행되어야 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4BsnajZafEI"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if USE_CUDA else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8fuDdBOafEO",
        "outputId": "9bd58259-5679-49e4-8593-ae1a13a8c96a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Nov 13 14:49:07 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    25W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC9xHrlt4LL9"
      },
      "source": [
        "##2. Preprocess data\n",
        "- Vocab (단어장) 을 만듭니다.\n",
        "- Iterator 를 만듭니다. (Iterator 를 통해 batch training 을 위한 batching 과 padding, 그리고 데이터 내 단어들의 인덱스 변환이 이루어집니다.)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suJRz9fgur1_",
        "outputId": "3d2fd1f4-a622-4d63-8347-3766c598d4bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data,\n",
        "                 max_size = MAX_VOCAB_SIZE,\n",
        "                 vectors = \"glove.6B.100d\",\n",
        "                 unk_init = torch.Tensor.normal_                 \n",
        "                 )\n",
        "LABEL.build_vocab(train_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:33, 2.19MB/s]                           \n",
            "100%|█████████▉| 399431/400000 [00:16<00:00, 22591.83it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES2qQ9kdu71e",
        "outputId": "27e29f0b-1f2c-438f-9bf7-7e6ea2ce2840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOD6AiIwKu-G"
      },
      "source": [
        "# Batching - construct iterator\n",
        "BATCH_SIZE = 32   \n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_sizes = (BATCH_SIZE, BATCH_SIZE, BATCH_SIZE),\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_tAoIcUMp3v"
      },
      "source": [
        "##3. Build Model\n",
        "- Embedding layer, Transformer layer, Fully-connected layer 로 이루어진 모델을 만듭니다.\n",
        "- Classification task 에 활용하기 위해 기존 Seq2Seq Transformer 를 변형하여, Transformer Encoder 만을 활용합니다.\n",
        "- Positional Encoding 식\n",
        "> $PE_(pos,2i) =sin(pos/10000^{2i/d_{model}})$  \n",
        "> $PE_(pos,2i+1) =cos(pos/10000^{2i/d_{model}})$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB9WQX3yrC2P"
      },
      "source": [
        "class PositionalEnc(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        \n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6slAdlS5giEY"
      },
      "source": [
        "class TransformerNet(nn.Module):    ## HW: TransformerNet 클래스에 추가되어야 할 파라미터를 한개 더 적어보자.\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_heads, n_layers, dropout, pad_idx):\n",
        "    # def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_heads, n_layers, dropout, pad_idx, length = MAX_LEN):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Define Layers\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        # Positional encoding layer\n",
        "        self.pe = PositionalEnc(embedding_dim) \n",
        "        # self.pe = PositionalEnc(embedding_dim, max_len=length)    ## HW: PositionalEnc 클래스의 max_len 에 전달될 값을 적어주자.\n",
        "\n",
        "        # Encoder layer\n",
        "        enc_layer = nn.TransformerEncoderLayer(embedding_dim, n_heads, hidden_dim, dropout=dropout)\n",
        "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers = n_layers)\n",
        "      \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "        # self.fc = nn.Linear(embedding_dim*length, output_dim)  ## HW: Fully-connected layer 의 input dimension 값을 다시 적어주자.\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        # text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        pos_encoded = self.pe(embedded)\n",
        "        trans_out = self.encoder(pos_encoded)\n",
        "        # trans_out = [sent len, batch_size, emb_dim]\n",
        "\n",
        "        pooled = trans_out.mean(0)\n",
        "        final = self.fc(self.dropout(pooled))\n",
        "\n",
        "        ## TO-DO ##\n",
        "        # Transformer 로 encoding 한 sequence 로부터, 한개의 확률값을 얻어낼 다른 방법을 구현해보자.\n",
        "\n",
        "        # 1) Prediction 을 위한 1개의 vector 로서 마지막 token 의 representation 을 취해보자. \n",
        "\n",
        "        # last = trans_out[-1,:] \n",
        "        # final = self.fc(self.dropout(last))\n",
        "  \n",
        "\n",
        "        # 2) HOMEWORK: Transformer 출력의 모든 값으로부터 곧바로 1개의 scalar 값을 계산하는 fc layer 를 만들어보자.\n",
        "        # batch = trans_out.shape[1]\n",
        "        # trans_re = trans_out.permute(1,0,2).reshape(batch,-1)                     # Permute, Reshape trans_out\n",
        "        # final = self.fc(trans_re)        \n",
        "\n",
        "\n",
        "        \n",
        "        return final\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fTDWd8RhEEl"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = 1\n",
        "N_HEADS = 2  #embedding_dim must be divisible by n_heads\n",
        "N_LAYERS = 1\n",
        "DROPOUT = 0.5\n",
        "\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "\n",
        "model = TransformerNet(INPUT_DIM,      \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_HEADS,\n",
        "            N_LAYERS, \n",
        "            DROPOUT,\n",
        "            PAD_IDX)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCUKXn94afEf",
        "outputId": "15d210cd-373c-404d-96a1-b6b7f0628ac4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print('The model has {:,} trainable parameters'.format(count_parameters(model)))\n",
        "\n",
        "# load pretrained embeddings\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,566,929 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDy-PGhSQcTd"
      },
      "source": [
        "## 4. Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7-5uM9bhTe3"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "model= model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7exIxGaZafE4"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Eb16jU0afFA"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "              \n",
        "        predictions = model(batch.text[0]).squeeze(1)\n",
        "        # predictions = model(batch.text).squeeze(1)   ## HOMEWORK: 데이터 입력이 고정 길이로 바뀌었을때의 prediction 값을 다시 써보자.\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8da_fbPRQ9I3"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text[0]).squeeze(1)\n",
        "            # predictions = model(batch.text).squeeze(1)  ## HOMEWORK: 데이터 입력이 고정 길이로 바뀌었을때의 prediction 값을 다시 써보자.\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZhS9Q2fSLyr"
      },
      "source": [
        "### *Do Training!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K46LhrQ7012J",
        "outputId": "bc13d895-ab4e-4a87-edfa-2c67dbd0ed78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'trans-model.pt')\n",
        "\n",
        "    print('Epoch: {:02}'.format(epoch+1))\n",
        "    print('\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%'.format(train_loss, train_acc*100))\n",
        "    print('\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%'.format(valid_loss, valid_acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 0.514 | Train Acc: 72.17%\n",
            "\t Val. Loss: 0.372 |  Val. Acc: 84.89%\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.317 | Train Acc: 86.75%\n",
            "\t Val. Loss: 0.342 |  Val. Acc: 86.82%\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.236 | Train Acc: 90.83%\n",
            "\t Val. Loss: 0.365 |  Val. Acc: 87.98%\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.177 | Train Acc: 93.23%\n",
            "\t Val. Loss: 0.442 |  Val. Acc: 88.27%\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.128 | Train Acc: 95.30%\n",
            "\t Val. Loss: 0.443 |  Val. Acc: 88.40%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En4SX_RA02k4",
        "outputId": "cda4432a-7fd9-4222-971f-64990cfe5031",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.load_state_dict(torch.load('trans-model.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print('Test Loss: {:.3f} | Test Acc: {:.2f}%'.format(test_loss, test_acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.349 | Test Acc: 86.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EtTQaIdafFL"
      },
      "source": [
        "## 5. Test model\n",
        "우리가 직접 예문을 작성해서 트레인된 모델에서 예문을 어떻게 평가하는지 확인합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hxev65tafFQ"
      },
      "source": [
        "# 토크나이저로 spacy 를 사용합니다.\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "# 사용자가 입력한 sentence 를 훈련된 모델에 넣었을때의 결과값을 확인합니다.\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  # Tokenization\n",
        "    print(tokenized)\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]   # 위에서 만든 vocab 에 부여된 index 로 indexing\n",
        "    # indexed = [indexed[i] if i<len(indexed) else TEXT.vocab.stoi['<PAD>'] for i in range(MAX_LEN) ] # 사용자가 직접 입력한 문장의 길이가 MAX_LEN 에 못 미칠때 나머지 부분을 패딩해주는 코드\n",
        "    print(indexed)\n",
        "    tensor = torch.LongTensor(indexed).to(device)   # indexing 된 sequence 를 torch tensor 형태로 만들어줌.\n",
        "    print(tensor.shape)\n",
        "    tensor = tensor.unsqueeze(1)   # 입력 텐서에 batch 차원을 만들어줌.\n",
        "    prediction = torch.sigmoid(model(tensor))  # 모델에 입력한 후 확률값 도출을 위한 sigmoid 적용 \n",
        "    return prediction.item() # prediction 값 출력"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIk_EjmoSFdU",
        "outputId": "fe82b4ad-d20e-41a7-eff7-cad618c26219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model, \"This film is terrible\") #아주 낮은 값의 확률이 도출되는 것을 확인할 수 있습니다.(부정)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'film', 'is', 'terrible']\n",
            "[66, 24, 9, 447]\n",
            "torch.Size([4])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0018361395923420787"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1ZZJbxaSFaa",
        "outputId": "161d479f-e7c1-4ca5-8af1-eb35c695fb18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict_sentiment(model, \"This film is great\") #아주 높은 값의 확률이 도출되는 것을 확인할 수 있습니다. (긍정)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'film', 'is', 'great']\n",
            "[66, 24, 9, 103]\n",
            "torch.Size([4])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9985785484313965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wEdPh2wC9Tbb"
   },
   "source": [
    "# IAB - Hands-on Tutorial for Link Analysis\n",
    "\n",
    "Welcome to IAB - hands-on tutorial for link analysis. \n",
    "In this tutorial, we will study several techniques for link analysis in graphs. \n",
    "This tutorial consists of two sessions and one homework, and each of them will handle the following topic:\n",
    "\n",
    "* **Session 1**. Tutorial on PageRank - Part 1 (60 mins)\n",
    "* **Session 2**. Tutorial on PageRank - Part 2 (60 mins)\n",
    "* **Session 3**. Tutorial on Topic-specific PageRank (120 mins)\n",
    "* <span style=\"color:blue\">**Homework**. Implementation of HITS</span>\n",
    "\n",
    "We recommend fully understanding the lecture videos related to link analysis (or ranking) models such as PageRank, Topic-specific PageRank, and HITS before entering this tutorial since we will **NOT** explain the theoretical backgrounds on these techniques during the tutorial. \n",
    "We will mainly focus on how to implement the algorithms of those models and how to rank nodes in real-world graphs using those ranking models. \n",
    "\n",
    "The main contributors of this material are as follows:\n",
    "* *Junghoon Kim* (rlawjdgns434@snu.ac.kr)\n",
    "* *Minyong Cho* (minyongcho@snu.ac.kr)\n",
    "* *U Kang* (ukang@snu.ac.kr)\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peno912F9Tbd"
   },
   "source": [
    "-----\n",
    "## Homework. Implementation of HITS\n",
    "In this homework, you will implement HITS in Python. \n",
    "The main goals of this homework are summarized as follows:\n",
    "* **Goal 1.** How to implement HITS based on sparse matrices using `numpy` and `scipy` in Python\n",
    "* **Goal 2.** To perform a qualitative analysis of the ranking result from HITS in real-world networks\n",
    "\n",
    "The outline of this homework is as follows:\n",
    "* **Step 1.** Review HITS algorithm\n",
    "* **Step 2.** Implement HITS algorithm - the sparse matrix version\n",
    "* **Step 3.** Validate your HITS implementation\n",
    "* **Step 4.** Qualitative analysis of the ranking result from HITS\n",
    "\n",
    "<span style=\"color:blue\">Note that we will evaluate the result from Step 2 as this homework. Before submittig your homework, please verify if your implementation is correct at Step 3. <span>\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GxN54ETu9Tbe"
   },
   "source": [
    "-----\n",
    "### Step 1. Review HITS algorithm\n",
    "\n",
    "In this step, we will briefly review HITS algorithm which is another global node ranking model in graphs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dH4TqizC9Tbf"
   },
   "source": [
    "#### Step 1-1. Mathematical definition of HITS\n",
    "Given an adjacency matrix of a graph, HITS computes the hub and authority score vectors which can be used for ranking nodes in the graph. \n",
    "\n",
    "##### Problem definition of HITS\n",
    "* **Input**: adjacency matrix $\\mathbf{A}\\in \\mathbb{R}^{n \\times n}$ of a graph $G=(V, E)$\n",
    "* **Output**: hub score vector $\\mathbf{h} \\in \\mathbb{R}^{n}$, and authority score vector $\\mathbf{a} \\in \\mathbb{R}^{n}$ such that\n",
    "\n",
    "$$\n",
    "\\mathbf{h} = \\mathbf{A}\\mathbf{a} \\\\\n",
    "\\mathbf{a} = \\mathbf{A}^{\\top}\\mathbf{h}\n",
    "$$\n",
    "\n",
    "* The above equations are called the equations for HITS.\n",
    "\n",
    "Note that HITS does not require the row-normalized adjacency matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4IyOqXEc9Tbf"
   },
   "source": [
    "#### Step 1-2. Iterative Algorithm for HITS\n",
    "As described in the lecture video, the hub and authority score vectors, $\\mathbf{h}$ and $\\mathbf{a}$, are obtained by iteratively computing the equations for HITS.   \n",
    "Note that for each iteration, we need to L2-normalize the vectors $\\mathbf{h}$ and $\\mathbf{a}$.\n",
    "The following pseudo-code represents the iterative algorithm for HITS. \n",
    "\n",
    "<img src=\"./images/iterative-algorithm-hits.png\" width=\"400\">\n",
    "\n",
    "Implement the iterative algorithm in Python. \n",
    "\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OW1vf8n79Tbg"
   },
   "source": [
    "### Step 2. Implement HITS algorithm - the sparse matrix version\n",
    "Implement the sparse matrix version of HITS algorithm in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUl-u1n19Tbg"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import numpy\n",
    "except:\n",
    "    !pip install numpy\n",
    "    import numpy\n",
    "try:\n",
    "    import scipy\n",
    "except:\n",
    "    !pip install scipy\n",
    "    import scipy    \n",
    "try:\n",
    "    import matplotlib\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib\n",
    "try:\n",
    "    import pandas\n",
    "except:\n",
    "    !pip install pandas\n",
    "    import pandas\n",
    "try:\n",
    "    from IPython.display import display \n",
    "except:\n",
    "    !pip install ipython\n",
    "    from IPython.display import display "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dk-PcRXc9Tbj"
   },
   "source": [
    "#### Step 2-2. Implement the phase for loading the graph dataset\n",
    "In this step, we will implement the phase for loading the graph dataset of the sparse matrix version of HITS. \n",
    "We first need to import the following packages for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9x2-dtN9Tbl"
   },
   "outputs": [],
   "source": [
    "# the below commands restrict the number of computation threads to 1\n",
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" \n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, find\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ByJ9bKNg9Tbm"
   },
   "source": [
    "As in the previous sessions, we implement the following function for loading graph datasets.\n",
    "Note that we do not need to modify the function since the functionality in the version is the same with that of Session 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7XdVrEd9Tbo"
   },
   "outputs": [],
   "source": [
    "class SparseHITS:\n",
    "    def load_graph_dataset(self, data_home, is_undirected=False):\n",
    "        '''\n",
    "        Load the graph dataset from the given directory (data_home)\n",
    "\n",
    "        inputs:\n",
    "            data_home: string\n",
    "                directory path conatining a dataset (edges.tsv, node_labels.tsv)\n",
    "            is_undirected: bool\n",
    "                if the graph is undirected\n",
    "        '''\n",
    "        # Step 1. self file paths from data_home\n",
    "        edge_path = \"{}/edges.tsv\".format(data_home)\n",
    "        \n",
    "        # Step 2. read the list of edges from edge_path\n",
    "        edges = np.loadtxt(edge_path, dtype=int)\n",
    "        n = int(np.amax(edges[:, 0:2])) + 1\n",
    "        \n",
    "        # Step 3. convert the edge list to the weighted adjacency matrix\n",
    "        rows = edges[:, 0]\n",
    "        cols = edges[:, 1]\n",
    "        weights = edges[:, 2]\n",
    "        self.A = csr_matrix((weights, (rows, cols)), shape=(n, n), dtype=float)\n",
    "        if is_undirected == True:\n",
    "            self.A = self.A + self.A.T\n",
    "        self.AT = self.A.T\n",
    "                \n",
    "        # Step 4. set n (# of nodes) and m (# of edges)\n",
    "        self.n = self.A.shape[0]     # number of nodes\n",
    "        self.m = self.A.nnz          # number of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nY9zieqJ9Tbq"
   },
   "outputs": [],
   "source": [
    "class SparseHITS(SparseHITS):\n",
    "    def load_node_labels(self, data_home):\n",
    "        '''\n",
    "        Load the node labels from the given directory (data_home)\n",
    "\n",
    "        inputs:\n",
    "            data_home: string\n",
    "                directory path conatining a dataset\n",
    "        '''\n",
    "        label_path = \"{}/node_labels.tsv\".format(data_home)\n",
    "        self.node_labels = pd.read_csv(label_path, sep=\"\\t\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8D-0mAPV9Tbs"
   },
   "source": [
    "Let's check if the function is correctly implemented. \n",
    "We will use the small dataset at `./data/small` as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9Bz6KFT9Tbs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number n of nodes: 29\n",
      "The number m of edges: 376\n"
     ]
    }
   ],
   "source": [
    "hits = SparseHITS()\n",
    "hits.load_graph_dataset('./data/small', is_undirected=False)\n",
    "print(\"The number n of nodes: {}\".format(hits.n))\n",
    "print(\"The number m of edges: {}\".format(hits.m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCj3Ji2i9Tbu"
   },
   "source": [
    "#### Step 2-3. Implement the iterative phase (Homework)\n",
    "\n",
    "Contrary to PageRank, HITS does not need a normalization phase for the adjacency matrix. \n",
    "In this step, we implement the iterative phase of HITS in the following algorithm.\n",
    "\n",
    "<img src=\"./images/iterative-algorithm-hits.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVdinWSz9Tbv"
   },
   "outputs": [],
   "source": [
    "class SparseHITS(SparseHITS):\n",
    "    def iterate_HITS(self, epsilon=1e-9, maxIters=100):\n",
    "        '''\n",
    "        ///Homework!///\n",
    "        Iterate the HITS equation to obatin the hub & authority score vectors\n",
    "        \n",
    "        inputs:\n",
    "            epsilon: float\n",
    "                the error tolerance of the iteration\n",
    "            maxIters: int\n",
    "                the maximum number of iterations\n",
    "                \n",
    "        outputs:\n",
    "            h: np.ndarray (n x 1 vector)\n",
    "                the final hub score vector\n",
    "            a: np.ndarray (n x 1 vector)\n",
    "                the final authority score vector\n",
    "            h_residuals: list\n",
    "                the list of hub residuals over the iteration\n",
    "            a_residuals: list\n",
    "                the list of authority residuals over the iteration\n",
    "\n",
    "        '''        \n",
    "        # From ==========================\n",
    "        # implement the HITS algorithm\n",
    "        # To ============================\n",
    "        \n",
    "        # since SVD is not unique, h and a could be negative according to a random seed\n",
    "        # in this case, we need to make the scores non-negative and L2-normalize them out\n",
    "        h = h * np.sign(h)\n",
    "        h = h / np.linalg.norm(h, 2)\n",
    "        a = a * np.sign(a)\n",
    "        a = a / np.linalg.norm(a, 2)\n",
    "        \n",
    "        return h, a, h_residuals, a_residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9oNpWtbs9Tby"
   },
   "source": [
    "Let's check the implementation is correctly performed. \n",
    "Please check ranking results based on hub and authority scores using `pandas`. \n",
    "\n",
    "**Homework. ** Print your top-$5$ ranking results on the files `hub.csv` and `auth.csv`, respectively.\n",
    "* format: each line print node id and its hub or authority score where they are comma-separated, i.e., `node_id, score`. Each score should be down to $4$ places of decimals. \n",
    "* `hub.csv`: it should contain top-$5$ rankings sorted in the decreasing order of the hub scores. \n",
    "* `auth.csv`: it should contain top-$5$ rankings sorted in the decreasing order of the authority scores. \n",
    "* To write an object of `pandas` to a file, please try to use `to_csv` function of `pandas`. \n",
    "    - https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUwzCR299Tb0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def rank_nodes(ranking_scores, topk=-1):\n",
    "    sorted_nodes = np.flipud(np.argsort(ranking_scores))\n",
    "    sorted_scores = ranking_scores[sorted_nodes]\n",
    "    ranking_results = pd.DataFrame()\n",
    "    ranking_results[\"node_id\"] = sorted_nodes\n",
    "    ranking_results[\"score\"] = sorted_scores\n",
    "    \n",
    "    return ranking_results[0:topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9cwPJj639Tb3"
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'h' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3938c1646da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparseHITS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_graph_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/small'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_undirected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_HITS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxIters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Top-5 rankings based on the hub score vector:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-fffd8a30a6ec>\u001b[0m in \u001b[0;36miterate_HITS\u001b[0;34m(self, epsilon, maxIters)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# since SVD is not unique, h and a could be negative according to a random seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# in this case, we need to make the scores non-negative and L2-normalize them out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'h' referenced before assignment"
     ]
    }
   ],
   "source": [
    "hits = SparseHITS()\n",
    "hits.load_graph_dataset('./data/small', is_undirected=False)\n",
    "h, a, _, _ = hits.iterate_HITS(epsilon=1e-9, maxIters=100)\n",
    "\n",
    "print(\"Top-5 rankings based on the hub score vector:\")\n",
    "display(rank_nodes(h, 5))\n",
    "\n",
    "print(\"Top-5 rankings based on the authority score vector\")\n",
    "display(rank_nodes(a, 5))\n",
    "\n",
    "# Homework!\n",
    "# Print your results on files 'hub.csv' and 'auth.csv', respectively.\n",
    "# Reference: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html\n",
    "# rank_nodes(h,5).to_csv('hub.csv', sep=',', index=False, header=False, float_format='%.4f')\n",
    "# rank_nodes(a,5).to_csv('auth.csv', sep=',', index=False, header=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2oj20f69Tb5"
   },
   "source": [
    "-----\n",
    "### Step 3. Validate your HITS implementation\n",
    "\n",
    "Validate the implementation of HITS.\n",
    "Similarly to PageRank, check if the residuals of the iterative algorithm monotonically decrease, and compare between the exact and iterative solutions of HITS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZLpjFLIw9Tb6"
   },
   "source": [
    "#### Step 3-1. Check if the residuals of the iterative algorithm monotonically decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGdq7R5n9Tb6"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 13}) # set the font-size in the figure\n",
    "\n",
    "def plot_residuals(residuals, title):\n",
    "    plt.semilogy(residuals, marker='o', markersize=5)\n",
    "    plt.title(title)\n",
    "    plt.ylim(ymin=1e-10, ymax=1e1)\n",
    "    plt.ylabel('Residual')\n",
    "    plt.xlabel('# of iterations')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gwTAm-YJ9Tb7"
   },
   "source": [
    "Let's check the plot for the hub residuals first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IgUaOfLE9Tb8"
   },
   "outputs": [],
   "source": [
    "hits = SparseHITS()\n",
    "hits.load_graph_dataset('./data/small', is_undirected=False)\n",
    "h, a, h_residuals, a_residuals = hits.iterate_HITS(epsilon=1e-9, maxIters=100)\n",
    "\n",
    "plot_residuals(h_residuals, 'Change of Hub Residuals from HITS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MLnf5o4w9Tb-"
   },
   "source": [
    "Next, the following will plot the authority residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGEZgduT9Tb_"
   },
   "outputs": [],
   "source": [
    "plot_residuals(a_residuals, 'Change of Authority Residuals from HITS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWQVWfkI9TcB"
   },
   "source": [
    "As you can see, those residuals monotonically decrease as the number of iteration increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BwV3Eqpo9TcB"
   },
   "source": [
    "#### Step 3-2. Check if the iterative solution is equal to the exact solution of HITS\n",
    "\n",
    "As explained in the lecture video, we can directly compute the hub ans authority score vectors of HITS as follows:\n",
    "* The hub score vector $\\mathbf{h}$ is the principle eigenvector of $\\mathbf{A}\\mathbf{A}^{\\top}$.\n",
    "* The authority score vector $\\mathbf{a}$ is the principle eigenvector of $\\mathbf{A}^{\\top}\\mathbf{A}$.\n",
    "\n",
    "The principle eigenvector of a matrix is an eigenvector of the largest eigenvalue. \n",
    "Suppose the Singular Value Decomposition (SVD) of the adjacency matrix is $\\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^{\\top}$. Then,\n",
    "* $\\mathbf{h}$ is the first (most left) vector of $\\mathbf{U}$. \n",
    "* $\\mathbf{a}$ is the first (most left) vector of $\\mathbf{V}$.\n",
    "\n",
    "We will not describe the detailed proofs for the above statements, but we can use them as the exact solutions for the hub and authority score vectors. \n",
    "\n",
    "We will implement the following function to compute the exact solutions. \n",
    "Note that since the adjacency matrix $\\mathbf{A}$ is a sparse matrix, we will use `svds` (sparse SVD) in `scipy`.\n",
    "* `svds`: this performs SVD on a sparse matrix\n",
    "    - https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8epiiIL9TcB"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "class SparseHITS(SparseHITS):\n",
    "    def compute_exact_HITS(self):\n",
    "        '''\n",
    "        Compute the exact hub & authority score vectors from the closed form\n",
    "\n",
    "        outputs:\n",
    "            h: np.ndarray (n x 1 vector)\n",
    "                the final hub score vector\n",
    "            a: np.ndarray (n x 1 vector)\n",
    "                the final authority score vector\n",
    "        '''\n",
    "        h, s, a = svds(self.A, k=1)\n",
    "        \n",
    "        h = np.asarray(h).flatten()   \n",
    "        a = np.asarray(a).flatten()\n",
    "        \n",
    "        return h, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ljQgRjJY9TcE"
   },
   "source": [
    "Let's check the error between the exact and iterative solutions of HITS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-cUdMDq9TcF"
   },
   "outputs": [],
   "source": [
    "hits = SparseHITS()\n",
    "hits.load_graph_dataset('./data/small', is_undirected=False)\n",
    "h_exact, a_exact = hits.compute_exact_HITS()\n",
    "h_iter, a_iter, _, _ = hits.iterate_HITS(epsilon=1e-9, maxIters=100)\n",
    "\n",
    "h_error = np.linalg.norm(h_exact - h_iter, 1)\n",
    "print(\"Error between exact and iterative hub scores: {:e}\".format(h_error))\n",
    "\n",
    "a_error = np.linalg.norm(a_exact - a_iter, 1)\n",
    "print(\"Error between exact and iterative authority scores: {:e}\".format(a_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mgPjpFSV9TcH"
   },
   "source": [
    "-----\n",
    "### Step 4. Qualitative analysis of the ranking result from HITS\n",
    "\n",
    "Now, we will do a qualitative analysis of the ranking result from HITS on a real-world graph. \n",
    "For this, we first use the following code which is already implemented through the previous session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCkqBBFC9TcH"
   },
   "outputs": [],
   "source": [
    "class SparseHITS(SparseHITS):\n",
    "    def rank_nodes(self, ranking_scores, topk=-1):\n",
    "        '''\n",
    "        Rank nodes in the order of given ranking scores. \n",
    "        This function reports top-k rankings. \n",
    "\n",
    "        inputs:\n",
    "            ranking_scores: np.ndarray\n",
    "                ranking score vector\n",
    "            topk: int\n",
    "                top-k ranking parameter, default is -1 indicating report all ranks\n",
    "        '''\n",
    "        sorted_nodes = np.flipud(np.argsort(ranking_scores)) # argsort in the descending order\n",
    "        sorted_scores = ranking_scores[sorted_nodes]         # sort the ranking scores\n",
    "        ranks = range(1, self.n+1) # 0~n-1\n",
    "\n",
    "        result_labels = self.node_labels.iloc[sorted_nodes][0:topk]\n",
    "        result_labels.insert(0, \"rank\", ranks[0:topk])\n",
    "        result_labels[\"score\"] = sorted_scores[0:topk]\n",
    "        result_labels.reset_index(drop = True, inplace = True)\n",
    "        return result_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xadOeMow9TcJ"
   },
   "source": [
    "The dataset used in this step is *enron* at `./data/enron` which has been used in Session 2. \n",
    "Please refer to Session 2 for the detailed description for the dataset. \n",
    "\n",
    "After loading the dataset, we will compute the hub ans authority score vectors of HITS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OD2vxHUh9TcJ"
   },
   "outputs": [],
   "source": [
    "data_home = './data/enron'\n",
    "hits = SparseHITS()\n",
    "hits.load_graph_dataset(data_home, is_undirected=False)\n",
    "hits.load_node_labels(data_home)\n",
    "h, a, h_residuals, a_residuals = hits.iterate_HITS(epsilon=1e-9, maxIters=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgY3Ozzt9TcL"
   },
   "source": [
    "Let's check the top-10 rankings based on the hub score vector in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9vZSs029TcL"
   },
   "outputs": [],
   "source": [
    "print(\"Top-10 rankings based on the hub score vector:\")\n",
    "display(hits.rank_nodes(h, topk=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_CiDKBM9TcN"
   },
   "source": [
    "Let's check the top-10 rankings based on the authority score vector in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFfQYm3E9TcN"
   },
   "outputs": [],
   "source": [
    "print(\"Top-10 rankings based on the authority score vector:\")\n",
    "display(hits.rank_nodes(a, topk=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ls1yHtBx9TcP"
   },
   "source": [
    "-----\n",
    "## Homework. Summary\n",
    "\n",
    "In this homework, you implemented HITS algorithm (the sparse matrix version) in Python. \n",
    "More specifically, you are able to answer the following goals now. \n",
    "\n",
    "* **Goal 1.** How to implement HITS based on sparse matrices using `numpy` and `scipy` in Python\n",
    "    - You implemented the iterative algorithm for HITS based on sparse matrices.\n",
    "* **Goal 2.** To perform a qualitative analysis of the ranking result from HITS in real-world networks\n",
    "    - You performed a qualitative analysis on the `enron` dataset which is a real-world network."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "(Homework) Implementation of HITS.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

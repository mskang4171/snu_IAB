{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_basic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwlPAA8ZJUsr"
      },
      "source": [
        "Copyright (C) 2020 Software Platform Lab, Seoul National University\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
        "\n",
        "you may not use this file except in compliance with the License. \n",
        "\n",
        "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 \n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software \n",
        "\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS, \n",
        "\n",
        "\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
        "\n",
        "\n",
        "See the License for the specific language governing permissions and\n",
        "\n",
        "\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki_RHIwPJvyn"
      },
      "source": [
        "# 1. PyTorch Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5N1npMVQqJz"
      },
      "source": [
        "## Tensor\n",
        "\n",
        "Let's create a Tensor in PyTorch. PyTorch Tensors are similar to NumPy ndarrays. In order to create an uninitialized Tensor object, we use `torch.empty(*size)` API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFZ3bfVsQz_p",
        "outputId": "25b6f45b-e399-4edd-cad2-106b05722ada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# Create 2X3 2-dimensional Tensor (Matrix)\n",
        "x = torch.empty(2, 3)\n",
        "\n",
        "# Create 2X3X4 3-dimensional Tensor\n",
        "y = torch.empty(2, 3, 4)\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.4836e-35, 0.0000e+00, 1.6255e-43],\n",
            "        [6.4460e-44, 1.3733e-43, 1.3593e-43]])\n",
            "tensor([[[2.3338e-35, 0.0000e+00, 7.0065e-44, 6.7262e-44],\n",
            "         [6.3058e-44, 6.8664e-44, 6.8664e-44, 6.3058e-44],\n",
            "         [6.8664e-44, 7.7071e-44, 1.1771e-43, 6.8664e-44]],\n",
            "\n",
            "        [[7.4269e-44, 8.1275e-44, 7.2868e-44, 7.4269e-44],\n",
            "         [8.1275e-44, 7.0065e-44, 7.2868e-44, 6.4460e-44],\n",
            "         [7.1466e-44, 7.7071e-44, 6.7262e-44, 7.8473e-44]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1HVJ5D4x2VA"
      },
      "source": [
        "We can also create initialized Tensor objects using the following APIs.\n",
        "\n",
        "* `torch.rand(*size)` : Initialize with random numbers from a uniform distribution on the interval [0, 1). \n",
        "* `torch.randn(*size)` : Initialize with random numbers from a normal distribution N(0, 1).\n",
        "* `torch.zeros(*size)` : Initialize with zeros.\n",
        "* `torch.ones(*size)` : Initialize with ones.\n",
        "\n",
        "Also, you can directly construct a Tensor from data using `torch.tensor()` API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqBA4_VcXCBe",
        "outputId": "7da0d949-db0c-4d85-abee-bb79db1db8de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_rand = torch.rand(2, 3)\n",
        "x_zeros = torch.zeros(2, 3)\n",
        "x_ones = torch.ones(2, 3)\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "\n",
        "print(x_rand)\n",
        "print(x_zeros)\n",
        "print(x_ones)\n",
        "print(x)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8971, 0.1654, 0.9918],\n",
            "        [0.7657, 0.0728, 0.6054]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWvA1LCbx2VF"
      },
      "source": [
        "The size of a Tensor object can be retrieved using `size()` API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QXhwKXex2VG",
        "outputId": "3c8ed5e5-fe87-408f-89a4-2adb3c5e048d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.empty(2, 3)\n",
        "print(x.size())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrE4WkZNUn9o"
      },
      "source": [
        "## Math Operations\n",
        "PyTorch is supporting multiple syntaxes for math operations. In this example, let's take a look at the division operation. You can also refer to the following link for the full list of PyTorch operations: https://pytorch.org/docs/stable/torch.html "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drceRvn4VGec",
        "outputId": "674df4a8-4940-4169-c678-c5f92849a8d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.tensor([[10, 20], [30, 40]])\n",
        "y = torch.tensor([[1, 2], [3, 4]])\n",
        "div = torch.div(x, y)\n",
        "\n",
        "print('x: \\n', x)\n",
        "print('y: \\n', y)\n",
        "print('div: \\n', div)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: \n",
            " tensor([[10, 20],\n",
            "        [30, 40]])\n",
            "y: \n",
            " tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "div: \n",
            " tensor([[10., 10.],\n",
            "        [10., 10.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jthhyswKkisO"
      },
      "source": [
        "Some useful operations are overloaded for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkmWJN_pY8Xf",
        "outputId": "78958e10-6e0c-4653-b989-b14aa2b8ca2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# This will produce the same result as the above.\n",
        "x = torch.tensor([[10, 20], [30, 40]])\n",
        "y = torch.tensor([[1, 2], [3, 4]])\n",
        "div = x/y\n",
        "\n",
        "# def __div__(self,val):\n",
        "# operation overide\n",
        "\n",
        "print('div: \\n', div)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "div: \n",
            " tensor([[10., 10.],\n",
            "        [10., 10.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnNhG69dgWsA"
      },
      "source": [
        "## Quiz 1\n",
        "**Define a function that takes two 2X2 Python lists as inputs and computes matrix multiplication operation. Return the result Tensor. Please note that inputs are given as Python lists, NOT Tensor objects. (HINT: use torch.matmul)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZyw665-gWsE",
        "outputId": "d444a11e-2028-47b5-a974-3907d6565322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "def matmul(x: list, y: list) -> torch.Tensor:\n",
        "    ############# Write here. ################\n",
        "    x_tensor = torch.FloatTensor(x)\n",
        "    y_tensor = torch.FloatTensor(y)\n",
        "    return torch.matmul(x_tensor,y_tensor)\n",
        "    ##########################################\n",
        "\n",
        "x = [[1, 2], [3, 4]]\n",
        "y = [[5, 6], [7, 8]]\n",
        "z = matmul(x, y)\n",
        "print(z)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[19., 22.],\n",
            "        [43., 50.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtiMyw7kx2VX"
      },
      "source": [
        "# 2. AutoGrad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4UKKwwsZa4I"
      },
      "source": [
        "AutoGrad provides automatic differentiation for all operations on PyTorch Tensors. Let's see how it works with some examples below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6Cuy6Jtx2VY"
      },
      "source": [
        "1) In order to use AutoGrad, you should create a Tensor object with its `requires_grad` attribute `True`. It will enable all operations on this Tensor object to be tracked so that its gradient value can be computed automatically through  backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nokr0hQNx2VZ",
        "outputId": "9b44b233-cdd8-438c-ca3c-8cd1edc6c007",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Note the difference between x and y\n",
        "x = torch.ones(2, 2)\n",
        "y = torch.ones(2, 2, requires_grad=True)\n",
        "\n",
        "print('x with requires_grad==False:\\n', x)\n",
        "print('y with requires_grad==True:\\n', y)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x with requires_grad==False:\n",
            " tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "y with requires_grad==True:\n",
            " tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5gmsi5x2Vc"
      },
      "source": [
        "2) After constructing Tensors with its `requires_grad` attribute `True`, do some operations on them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hf0jHNmx2Vc",
        "outputId": "16508bd8-aecd-40bf-c737-0cd324f88cd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "y = x + 2 # This is equivalent as y = x + torch.tensor([[2, 2], [2, 2]])\n",
        "out = y.mean()\n",
        "\n",
        "print(out)\n",
        "print(out.grad) # None & Error"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3., grad_fn=<MeanBackward0>)\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z058Am0x2Vf"
      },
      "source": [
        "3) Finally, do backpropagation on the final output Tensor `out` by calling `out.backward()`. Gradient value `d(out)/dx` will be automatically computed and stored at the `grad` attribute of the Tensor `x`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUZTzNhDx2Vf",
        "outputId": "7c5e73f8-fbb0-4242-dc78-b0df8cbe5392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "y = x + 2 \n",
        "out = y.mean()\n",
        "out.backward()\n",
        "\n",
        "# Let's check the gradient value d(out)/d(x)\n",
        "print(x.grad)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2500, 0.2500],\n",
            "        [0.2500, 0.2500]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2BQaWgux2Vj"
      },
      "source": [
        "Since $out = 0.25 \\sum_{i}{(x_i + 2)}$, $\\frac{\\partial{out}}{\\partial{x_i}}=0.25$ and the result is reasonale. Let's also take a look at a more complex example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN1gSF7Bx2Vj",
        "outputId": "18d88ffd-e7b1-47a6-b1c9-61d4a077f84e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.tensor([[1., 1.,], [1., 1.]], requires_grad=True)\n",
        "y = torch.tensor([[2., 2.,], [2., 2.]], requires_grad=True)\n",
        "z = x + y\n",
        "z = z * z\n",
        "out = z.mean()\n",
        "out.backward()\n",
        "\n",
        "print('x.grad: \\n', x.grad)\n",
        "print('y.grad: \\n', y.grad)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.grad: \n",
            " tensor([[1.5000, 1.5000],\n",
            "        [1.5000, 1.5000]])\n",
            "y.grad: \n",
            " tensor([[1.5000, 1.5000],\n",
            "        [1.5000, 1.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFjfcM6tx2Vm"
      },
      "source": [
        "$out = 0.25 \\sum_{i}{(x_i + y_i)^2}$ and, therefore $\\frac{\\partial{out}}{\\partial{x_i}} = 0.5 (x_i + y_i)$\n",
        "\n",
        "You can also check up the gradient value `d(out)/dy` from `y.grad` since `y` is also a Tensor that requires gradient. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgkBt_4Ix2Vn"
      },
      "source": [
        "In order to stop AutoGrad from tracking Tensor operations, you can wrap the code block in `with torch.no_grad():`. It will stop tracking of all Tensor operations in the wrapped code block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PaPhycIx2Vn",
        "outputId": "aa0f38da-1183-4361-9ca0-95e0e73521c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.tensor([[1., 1.,], [1., 1.]], requires_grad=True)\n",
        "print(x.requires_grad)\n",
        "y = (x * x)\n",
        "print(y.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y = (x * x)\n",
        "    print(y.requires_grad)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs3yizqwmxHs"
      },
      "source": [
        "## Quiz 2\n",
        "\n",
        "1. Define three 2X2 matrices (`X`, `Y` and `Z`) with random initial values.\n",
        "2. Compute `out = mean(XY + Z)` (use matrix multiplication, not element-wise multiplication)\n",
        "3. Compute and print gradient values of `out` with respect to `X`, `Y` and `Z`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhqP7g40o0z2",
        "outputId": "0b83bd3a-c901-4a07-dce5-afeef93ea739",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "############# Write here. ################\n",
        "def generate_tensor():\n",
        "  return torch.rand(2,2, requires_grad=True)\n",
        "\n",
        "X = generate_tensor()\n",
        "Y = generate_tensor()\n",
        "Z = generate_tensor()\n",
        "\n",
        "out = (torch.matmul(X,Y)+Z).mean()\n",
        "out.backward()\n",
        "\n",
        "print('X.grad: \\n', X.grad)\n",
        "print('Y.grad: \\n', Y.grad)\n",
        "print('Z.grad: \\n', Z.grad)\n",
        "##########################################"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X.grad: \n",
            " tensor([[0.2917, 0.4294],\n",
            "        [0.2917, 0.4294]])\n",
            "Y.grad: \n",
            " tensor([[0.1880, 0.1880],\n",
            "        [0.1312, 0.1312]])\n",
            "Z.grad: \n",
            " tensor([[0.2500, 0.2500],\n",
            "        [0.2500, 0.2500]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgFhwdh4kJlB"
      },
      "source": [
        "# 3. Dataset and DataLoader\n",
        "\n",
        "Data preparation is one of the main tasks in machine learning tasks. Hopefully, PyTorch is providing efficient tools to make data loading easy while maintaining the code readablility. In this section, let's learn PyTorch's `torch.utils.data.Dataset` and `torch.utils.data.DataLoder API` for data preparation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mHYbZmS06zb"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "`torch.utils.data.Dataset` is the abstract class representing a dataset. To make your own dataset class, you should first inherit `Dataset` class and then override the following methods. \n",
        "\n",
        "* `__len__` : it will enable `len(dataset)` to return the size of your custom dataset.\n",
        "* `__getitem__` : it will enable `dataset[i]` to index ith sample of your custom dataset.\n",
        "\n",
        "Let's take a look at the following example to see how it works. Before moving on, let's first prepare a toy dataset file that consists of 10 samples, each of them having `i%2` for the label and vector `[i, i+1, i+2]` for the image, and store it as a `.csv` format. This toy dataset will be used throughout the example. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4rNdqx6x2Vu",
        "outputId": "6e3c1854-483a-46e0-e7b1-949aa28d502e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import csv    \n",
        "\n",
        "# .csv file will be stored at ./dataset.csv\n",
        "filename = 'dataset.csv'\n",
        "f = open(filename, 'w', encoding='utf-8', newline='')\n",
        "wr = csv.writer(f)\n",
        "for i in range(8):\n",
        "    wr.writerow([i%2] + [i, i+1, i+2]) # (label, image)\n",
        "f.close()\n",
        "\n",
        "f = open(filename, 'r', encoding='utf-8')\n",
        "rdr = csv.reader(f)\n",
        "for line in rdr:\n",
        "    print(line)\n",
        "f.close()  "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '0', '1', '2']\n",
            "['1', '1', '2', '3']\n",
            "['0', '2', '3', '4']\n",
            "['1', '3', '4', '5']\n",
            "['0', '4', '5', '6']\n",
            "['1', '5', '6', '7']\n",
            "['0', '6', '7', '8']\n",
            "['1', '7', '8', '9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOmVJNiQx2Vx"
      },
      "source": [
        "Let's make a custom Dataset class that reads our `dataset.csv` dataset file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iEwa1-ayqWy"
      },
      "source": [
        "import torch \n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    # read input .csv dataset file and store in self.data as a pandas object\n",
        "    def __init__(self, file_path):\n",
        "        self.data = pd.read_csv(file_path, header=None)\n",
        "    \n",
        "    # data length is simply the length of self.data\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    # return a tuple of image and label at (index)th row of our self.data\n",
        "    def __getitem__(self, index):\n",
        "        label = self.data.iloc[index, 0] # First element is the label\n",
        "        image = self.data.iloc[index, 1:] # Remaining elements are the image vector\n",
        "        # convert the image into torch Tensor type\n",
        "        image = torch.tensor(image.tolist(), dtype=torch.float)\n",
        "        return image, label"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eovVTnP3x2Vy"
      },
      "source": [
        "Let us then instantiate our `CustomDataset` class and iterate through the data samples. Since we have `__len__` and `__getitem__` methods overriden, we can get the length of the dataset with `len(dataset)` and access to ith sample with `dataset[i]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcllAIWex2Vy",
        "outputId": "03b43c0d-837f-42b3-9a4d-39a9942127e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = CustomDataset('dataset.csv')\n",
        "for i in range(len(dataset)): # len을 정의하였기 때문에 사용 가능\n",
        "    print('%dth sample' % i)\n",
        "    image = dataset[i][0] # getitem을 정의하였기 때문에 사용 가능\n",
        "    label = dataset[i][1]\n",
        "    # image, label = dataset[i] # Same\n",
        "    print('image:', image, ', label:', label)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0th sample\n",
            "image: tensor([0., 1., 2.]) , label: 0\n",
            "1th sample\n",
            "image: tensor([1., 2., 3.]) , label: 1\n",
            "2th sample\n",
            "image: tensor([2., 3., 4.]) , label: 0\n",
            "3th sample\n",
            "image: tensor([3., 4., 5.]) , label: 1\n",
            "4th sample\n",
            "image: tensor([4., 5., 6.]) , label: 0\n",
            "5th sample\n",
            "image: tensor([5., 6., 7.]) , label: 1\n",
            "6th sample\n",
            "image: tensor([6., 7., 8.]) , label: 0\n",
            "7th sample\n",
            "image: tensor([7., 8., 9.]) , label: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8OZ9ZvVx2V0"
      },
      "source": [
        "## Transforms\n",
        "\n",
        "In many cases, we need to apply transformations on our sample images (i.e. normalization, image reshaping, etc.) We can easily implement such transforms with callable classes: we just need to implement `__call__` method and, if required, `__init__` method. Then, we can transform each sample of the dataset like this:\n",
        "```\n",
        "transform = Transform(params)\n",
        "transformed_sample = transform(sample)\n",
        "```\n",
        "As an example, let's implement two toy transforms: negation and addition. `__call__` method takes a sample of the dataset as an input and returns transformed sample as an output. Note that we can additionally define `__init__` method if required.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO0rT5avx2V1"
      },
      "source": [
        "class Negation(object):\n",
        "    def __call__(self, sample): # Callable\n",
        "        image = sample[0]\n",
        "        label = sample[1]\n",
        "        negative_image = -1. * image\n",
        "        return negative_image, label\n",
        "\n",
        "# negation_op = Negation() \n",
        "# negative_sample, label = negation_op(sample)\n",
        "\n",
        "class Addition(object):\n",
        "    def __init__(self, v):\n",
        "        self._v = v\n",
        "        \n",
        "    def __call__(self, sample):\n",
        "        image = sample[0]\n",
        "        label = sample[1]\n",
        "        added_image = image + self._v\n",
        "        return added_image, label\n",
        "\n",
        "# add_1_op = Addition(tensor_of_value_one)\n",
        "# add_2_op = Addition(tensor_of_value_two)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruMIreuUx2V3"
      },
      "source": [
        "Then, instantiate the transform classes. We can compose more than one transforms using `torchvision.transforms.Compose` API. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVLWhyTIx2V3"
      },
      "source": [
        "from torchvision import transforms\n",
        "added_one = Addition(1)\n",
        "negation = Negation()\n",
        "compose = transforms.Compose([added_one, negation])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9N1fDe_x2V5"
      },
      "source": [
        "Let's check how our transform works on a sample image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKmQcUf5x2V6",
        "outputId": "a1500df0-6a1f-446e-8536-dda789c834fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample = dataset[0]\n",
        "transformed_sample = compose(sample)\n",
        "other_transformed_sample = negation(added_one(sample))\n",
        "\n",
        "print('image before transformation:', sample[0])\n",
        "print('image after transformation:', transformed_sample[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image before transformation: tensor([0., 1., 2.])\n",
            "image after transformation: tensor([-1., -2., -3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lWtBx6xx2V8"
      },
      "source": [
        "Finally, we can redefine our custom Dataset to apply the transform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dJ7Iuxgx2V8",
        "outputId": "0af7e5d6-d3f3-4add-f894-966ea25934e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, file_path, transform=None):\n",
        "        self.data = pd.read_csv(file_path, header=None)\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        label = self.data.iloc[index, 0] \n",
        "        image = self.data.iloc[index, 1:] \n",
        "        image = torch.tensor(image.tolist(), dtype=torch.float)\n",
        "        sample = (image, label)\n",
        "        \n",
        "        # transform the image\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample) \n",
        "        \n",
        "        return sample\n",
        "\n",
        "transformed_dataset = CustomDataset('dataset.csv', transform=compose)\n",
        "\n",
        "for i in range(len(transformed_dataset)):\n",
        "    print('%dth sample' % i)\n",
        "    image = transformed_dataset[i][0]\n",
        "    label = transformed_dataset[i][1]\n",
        "    print('image:', image, ', label:', label) # 값에 모두 1을 더해서 negtaion이 된 것을 볼 수 있다."
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0th sample\n",
            "image: tensor([-1., -2., -3.]) , label: 0\n",
            "1th sample\n",
            "image: tensor([-2., -3., -4.]) , label: 1\n",
            "2th sample\n",
            "image: tensor([-3., -4., -5.]) , label: 0\n",
            "3th sample\n",
            "image: tensor([-4., -5., -6.]) , label: 1\n",
            "4th sample\n",
            "image: tensor([-5., -6., -7.]) , label: 0\n",
            "5th sample\n",
            "image: tensor([-6., -7., -8.]) , label: 1\n",
            "6th sample\n",
            "image: tensor([-7., -8., -9.]) , label: 0\n",
            "7th sample\n",
            "image: tensor([ -8.,  -9., -10.]) , label: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oFw7iH4x2V-"
      },
      "source": [
        "## DataLoader\n",
        "\n",
        "So far, we have learned how to construct a Dataset class from `.csv` file and apply transforms over the dataset. However, simply iterating over the dataset with `for` loop has potential problems because it does not support these features.\n",
        "* Batching data\n",
        "* Shuffling data\n",
        "* Loading data in parallel on multiple workers\n",
        "\n",
        "Luckily, PyTorch is providing `torch.utils.data.DataLoader` module, an iterator that can support all these features. The following example creates a Dataloader that shuffles data and batches it with `batch_size==4`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPTXgHuZx2V-"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transformed_dataset = CustomDataset('dataset.csv', transform=compose)\n",
        "dataloader = DataLoader(dataset=transformed_dataset,\n",
        "                        shuffle=True,\n",
        "                        batch_size=4)\n",
        "# dataloader = DataLoader(dataset=transformed_dataset,\n",
        "#                         shuffle=False,\n",
        "#                         batch_size=4)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHKskF9ax2WB"
      },
      "source": [
        "Finally, we can iterate over the dataset using the dataloader. Note that the resulting data is shuffled over the different epoches and batched with the size of 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CgQR2QOx2WB",
        "outputId": "86f6f847-7594-45ce-86f3-c45c8408bc10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(2):\n",
        "    print('Epoch %d\\n' % epoch)\n",
        "    for i, data in enumerate(dataloader):\n",
        "        images, labels = data\n",
        "        print('Batch %d' % i)\n",
        "        print('batched images:\\n', images)\n",
        "        print('batched labels:\\n', labels)\n",
        "        print('')\n",
        "    print('='*30)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "\n",
            "Batch 0\n",
            "batched images:\n",
            " tensor([[ -6.,  -7.,  -8.],\n",
            "        [ -7.,  -8.,  -9.],\n",
            "        [ -8.,  -9., -10.],\n",
            "        [ -4.,  -5.,  -6.]])\n",
            "batched labels:\n",
            " tensor([1, 0, 1, 1])\n",
            "\n",
            "Batch 1\n",
            "batched images:\n",
            " tensor([[-2., -3., -4.],\n",
            "        [-3., -4., -5.],\n",
            "        [-1., -2., -3.],\n",
            "        [-5., -6., -7.]])\n",
            "batched labels:\n",
            " tensor([1, 0, 0, 0])\n",
            "\n",
            "==============================\n",
            "Epoch 1\n",
            "\n",
            "Batch 0\n",
            "batched images:\n",
            " tensor([[-1., -2., -3.],\n",
            "        [-7., -8., -9.],\n",
            "        [-6., -7., -8.],\n",
            "        [-5., -6., -7.]])\n",
            "batched labels:\n",
            " tensor([0, 0, 1, 0])\n",
            "\n",
            "Batch 1\n",
            "batched images:\n",
            " tensor([[ -3.,  -4.,  -5.],\n",
            "        [ -2.,  -3.,  -4.],\n",
            "        [ -4.,  -5.,  -6.],\n",
            "        [ -8.,  -9., -10.]])\n",
            "batched labels:\n",
            " tensor([0, 1, 1, 1])\n",
            "\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB-UQ4I7x2WD"
      },
      "source": [
        "## Quiz 3\n",
        "\n",
        "Create a dataloader that satisfies the following conditions.\n",
        "1. Reads `dataset.csv` file\n",
        "2. Apply vector normalization transform (i.e. rescale the image vector `v` so that the vector size `||v||` equals 1)\n",
        "3. Shuffle and batch into the size of 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSwumVCex2WE",
        "outputId": "adab466b-70ba-4fd1-cf48-90a442cca1e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, file_path, transform=None):\n",
        "        self.data = pd.read_csv(file_path, header=None)\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        label = self.data.iloc[index, 0] \n",
        "        image = self.data.iloc[index, 1:] \n",
        "        image = torch.tensor(image.tolist(), dtype=torch.float)\n",
        "        sample = (image, label)\n",
        "        \n",
        "        # transform the image\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample) \n",
        "        \n",
        "        return sample\n",
        "\n",
        "class Normalization(object):\n",
        "    def __call__(self, sample):\n",
        "        ############# Write here. ################\n",
        "        image, label = sample\n",
        "        size = (image*image).sum() ** 0.5\n",
        "        return image/size, label\n",
        "        ##########################################\n",
        "\n",
        "############# Write here. ################\n",
        "normalization = Normalization()\n",
        "dataset = CustomDataset('dataset.csv', transform = normalization)\n",
        "dataloader = DataLoader(dataset=dataset,\n",
        "                        shuffle=True,\n",
        "                        batch_size=2)\n",
        "##########################################\n",
        "\n",
        "for epoch in range(2):\n",
        "    print('Epoch %d\\n' % epoch)\n",
        "    for i, data in enumerate(dataloader):\n",
        "        images, labels = data\n",
        "        print('Batch %d' % i)\n",
        "        print('batched images:\\n', images)\n",
        "        print('batched labels:\\n', labels)\n",
        "        print('')\n",
        "    print('='*30)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "\n",
            "Batch 0\n",
            "batched images:\n",
            " tensor([[0.4767, 0.5721, 0.6674],\n",
            "        [0.4915, 0.5735, 0.6554]])\n",
            "batched labels:\n",
            " tensor([1, 0])\n",
            "\n",
            "Batch 1\n",
            "batched images:\n",
            " tensor([[0.4558, 0.5698, 0.6838],\n",
            "        [0.3714, 0.5571, 0.7428]])\n",
            "batched labels:\n",
            " tensor([0, 0])\n",
            "\n",
            "Batch 2\n",
            "batched images:\n",
            " tensor([[0.2673, 0.5345, 0.8018],\n",
            "        [0.0000, 0.4472, 0.8944]])\n",
            "batched labels:\n",
            " tensor([1, 0])\n",
            "\n",
            "Batch 3\n",
            "batched images:\n",
            " tensor([[0.4243, 0.5657, 0.7071],\n",
            "        [0.5026, 0.5744, 0.6462]])\n",
            "batched labels:\n",
            " tensor([1, 1])\n",
            "\n",
            "==============================\n",
            "Epoch 1\n",
            "\n",
            "Batch 0\n",
            "batched images:\n",
            " tensor([[0.4558, 0.5698, 0.6838],\n",
            "        [0.4915, 0.5735, 0.6554]])\n",
            "batched labels:\n",
            " tensor([0, 0])\n",
            "\n",
            "Batch 1\n",
            "batched images:\n",
            " tensor([[0.2673, 0.5345, 0.8018],\n",
            "        [0.4767, 0.5721, 0.6674]])\n",
            "batched labels:\n",
            " tensor([1, 1])\n",
            "\n",
            "Batch 2\n",
            "batched images:\n",
            " tensor([[0.5026, 0.5744, 0.6462],\n",
            "        [0.3714, 0.5571, 0.7428]])\n",
            "batched labels:\n",
            " tensor([1, 0])\n",
            "\n",
            "Batch 3\n",
            "batched images:\n",
            " tensor([[0.4243, 0.5657, 0.7071],\n",
            "        [0.0000, 0.4472, 0.8944]])\n",
            "batched labels:\n",
            " tensor([1, 0])\n",
            "\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_high_level_apis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwlPAA8ZJUsr"
      },
      "source": [
        "Copyright (C) 2019 Software Platform Lab, Seoul National University\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
        "\n",
        "you may not use this file except in compliance with the License. \n",
        "\n",
        "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 \n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software \n",
        "\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS, \n",
        "\n",
        "\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
        "\n",
        "\n",
        "See the License for the specific language governing permissions and\n",
        "\n",
        "\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO8dQBJs5Yxh"
      },
      "source": [
        "## Defining a model in TensorFlow \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV9KmwLR_wBQ"
      },
      "source": [
        "In TensorFlow, various libraries regarding the model definition are provided under `tf.keras`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqWzzFUO79nx"
      },
      "source": [
        "### Model Subclassing\n",
        "We can build a fully-customizable model by subclassing [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model) and defining your own forward pass. Layers are created in the `__init__` method, provided by the [tf.keras.layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers)  and they are set as attributes of the class instance. The forward pass is defined in the `call` method. You can access model variables by `model.trainable_variables`.\n",
        "\n",
        "Below is an example of a linear regression model to be defined as a subclass of `tf.keras.Model`, and then be trained using loss function, gradient function and optimizer provided in [tf.keras.optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). Useful loss functions are also provided in [tf.keras.losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses). We will cover these in more detail as we go on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu-X05yCDq9V"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRHEy317_-s0"
      },
      "source": [
        "NUM_EXAMPLES = 2000\n",
        "toy_inputs = tf.random.normal([NUM_EXAMPLES, 1])\n",
        "noise = tf.random.normal([NUM_EXAMPLES, 1])\n",
        "toy_outputs = toy_inputs * 2 - 1 + noise * 1/4"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy1x6VF-_-s1",
        "outputId": "783bb934-a3b7-4704-fe76-bafc4200bcd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class ToyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        \"\"\"Define layers\"\"\"\n",
        "        super(ToyModel, self).__init__()\n",
        "        self.dense = tf.keras.layers.Dense(units=1)\n",
        "\n",
        "    def call(self, input):\n",
        "        \"\"\"Define forward pass.\"\"\"\n",
        "        result = self.dense(input)        \n",
        "        return result\n",
        "\n",
        "\n",
        "# The loss function to be optimized (MSE loss) mean squared error\n",
        "def loss(model, inputs, targets):\n",
        "    error = model(inputs) - targets\n",
        "    return tf.reduce_mean(tf.square(error))\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "model = ToyModel()\n",
        "print(\"Initial loss: {:.3f}\".format(loss(model, toy_inputs, toy_outputs)))\n",
        "print(\"Trainable variables:\")\n",
        "for var in model.trainable_variables:\n",
        "  print(\"\\t\", var.name, \": \", var.numpy())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial loss: 1.294\n",
            "Trainable variables:\n",
            "\t toy_model/dense/kernel:0 :  [[1.5476326]]\n",
            "\t toy_model/dense/bias:0 :  [0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ3w_EmG7shn",
        "outputId": "bbf63f00-3cff-4797-b222-c53221d2f12b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Training loop\n",
        "\n",
        "for i in range(300):\n",
        "    with tf.GradientTape() as tape: # GradientTape는 pytorch에서 autoGrad와 비슷. gradient를 사용하고 싶을 때 사용\n",
        "    # pytorch의 경우 with no grad로 gradient를 사용 안할 때 적어줘야함.\n",
        "        loss_value = loss(model, toy_inputs, toy_outputs)\n",
        "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    if i % 20 == 0:\n",
        "        print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, toy_inputs, toy_outputs)))\n",
        "\n",
        "print(\"Final loss: {:.3f}\".format(loss(model, toy_inputs, toy_outputs)))\n",
        "print(\"Trainable variables:\")\n",
        "for var in model.trainable_variables:\n",
        "  print(\"\\t\", var.name, \": \", var.numpy()) # 우리가 원한 2x - 1 을 잘 train한 것을 볼 수 있다."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at step 000: 1.245\n",
            "Loss at step 020: 0.589\n",
            "Loss at step 040: 0.297\n",
            "Loss at step 060: 0.168\n",
            "Loss at step 080: 0.110\n",
            "Loss at step 100: 0.084\n",
            "Loss at step 120: 0.073\n",
            "Loss at step 140: 0.068\n",
            "Loss at step 160: 0.066\n",
            "Loss at step 180: 0.065\n",
            "Loss at step 200: 0.064\n",
            "Loss at step 220: 0.064\n",
            "Loss at step 240: 0.064\n",
            "Loss at step 260: 0.064\n",
            "Loss at step 280: 0.064\n",
            "Final loss: 0.064\n",
            "Trainable variables:\n",
            "\t toy_model/dense/kernel:0 :  [[2.0041044]]\n",
            "\t toy_model/dense/bias:0 :  [-1.0066072]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8MEnHhAvskB"
      },
      "source": [
        "It's not required to set an input shape for the `tf.keras.Model` class since the parameters are set the first time input is passed to the layer.\n",
        "\n",
        "tf.keras.layers classes create and contain their own model variables that are tied to the lifetime of their layer objects. To share layer variables, share their objects.\n",
        "\n",
        "Below examples shows a new model that relies on the previous toy model. We are going to employ an additional bias to fit a slightly different data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFF5jQ___-s7",
        "outputId": "2ad58410-d474-4a35-859a-c6b76eb233df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "toy_outputs_2 = toy_outputs + 3\n",
        "\n",
        "class ToyModel2(tf.keras.Model):\n",
        "    def __init__(self, toy_model):\n",
        "        \"\"\"Define layers\"\"\"\n",
        "        super(ToyModel2, self).__init__()\n",
        "        self.toy_model = toy_model\n",
        "        self.b = tf.Variable(0., name='another_bias')\n",
        "\n",
        "    def call(self, input):\n",
        "        \"\"\"Define forward pass.\"\"\"\n",
        "        result = self.toy_model(input)        \n",
        "        return result + self.b\n",
        "\n",
        "\n",
        "model2 = ToyModel2(model)\n",
        "print(\"Initial loss: {:.3f}\".format(loss(model2, toy_inputs, toy_outputs_2)))\n",
        "print(\"Trainable variables:\")\n",
        "for var in model2.trainable_variables:\n",
        "  print(\"\\t\", var.name, \": \", var.numpy())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial loss: 9.050\n",
            "Trainable variables:\n",
            "\t toy_model/dense/kernel:0 :  [[2.0041044]]\n",
            "\t toy_model/dense/bias:0 :  [-1.0066072]\n",
            "\t another_bias:0 :  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZf0cTk7_-s9"
      },
      "source": [
        "We are only optimizing the additional bias. The weight and bias of toy_model_1 does not change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhNlE5mTw7bX",
        "outputId": "b31d0e2d-5120-4755-8ac4-9d95280afbfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Training loop\n",
        "for i in range(300):\n",
        "    with tf.GradientTape() as tape: # gradient를 추가한다.\n",
        "        loss_value = loss(model2, toy_inputs, toy_outputs_2)\n",
        "    grads = tape.gradient(loss_value, [model2.b]) # gradient w.r.t. `model2.b`, not `model2.trainable_variables`\n",
        "    optimizer.apply_gradients(zip(grads, [model2.b]))# optimize only `model2.b`\n",
        "    if i % 20 == 0:\n",
        "        print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model2, toy_inputs, toy_outputs_2)))\n",
        "\n",
        "print(\"Final loss: {:.3f}\".format(loss(model2, toy_inputs, toy_outputs_2)))\n",
        "print(\"Trainable variables:\")\n",
        "for var in model2.trainable_variables:\n",
        "  print(\"\\t\", var.name, \": \", var.numpy()) # another bias가 잘 학습되었다.\n",
        "  # model2의 graident를 확인해서 update하였기 때문에 기존 model의 variable은 변하지 않는다."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at step 000: 8.694\n",
            "Loss at step 020: 3.910\n",
            "Loss at step 040: 1.778\n",
            "Loss at step 060: 0.828\n",
            "Loss at step 080: 0.404\n",
            "Loss at step 100: 0.215\n",
            "Loss at step 120: 0.131\n",
            "Loss at step 140: 0.094\n",
            "Loss at step 160: 0.077\n",
            "Loss at step 180: 0.070\n",
            "Loss at step 200: 0.066\n",
            "Loss at step 220: 0.065\n",
            "Loss at step 240: 0.064\n",
            "Loss at step 260: 0.064\n",
            "Loss at step 280: 0.064\n",
            "Final loss: 0.064\n",
            "Trainable variables:\n",
            "\t toy_model/dense/kernel:0 :  [[2.0041044]]\n",
            "\t toy_model/dense/bias:0 :  [-1.0066072]\n",
            "\t another_bias:0 :  2.9907575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjAodT-v_-r7"
      },
      "source": [
        "## Convolutional Neural Networks\n",
        "Build simple CNN in TensorFlow.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LQHVwI1g_PF"
      },
      "source": [
        "### Preparing MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LydTwAzMhHw0",
        "outputId": "308f1827-8bfb-49a4-b9c3-3f3617fbe98b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Download the mnist dataset using keras\n",
        "data_train, data_test = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Parse images and labels (unpack)\n",
        "(train_images, train_labels) = data_train\n",
        "(test_images, test_labels) = data_test\n",
        "\n",
        "# Numpy reshape & type casting\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_labels = train_labels.astype('int64')\n",
        "test_labels = test_labels.astype('int64')\n",
        "\n",
        "\n",
        "# Normalizing the images to the range of [0., 1.]\n",
        "train_images /= 255.\n",
        "test_images /= 255.\n",
        "\n",
        "print(train_images.shape, train_labels.shape)\n",
        "print(test_images.shape, test_labels.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) (60000,)\n",
            "(10000, 28, 28, 1) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ5XuFPCBOZR"
      },
      "source": [
        "### Define the CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_USTku5_-r8"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "# Construct a tf.keras.model using tf.keras\n",
        "class MyCNN(Model):\n",
        "  def __init__(self):\n",
        "    super(MyCNN, self).__init__()\n",
        "    self.conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='valid')\n",
        "    self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='valid')\n",
        "    self.conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='valid')\n",
        "    self.maxpool = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.dense1 = tf.keras.layers.Dense(256, activation='relu')\n",
        "    self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.dense2(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "# Create model\n",
        "model = MyCNN()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk4Cg8gRpWH_"
      },
      "source": [
        "### Setting up training\n",
        "After the model is constructed, we specify optimizer and loss function. We can also monitor training using metrics:\n",
        "* `optimizer`: This field specifies which optimizer to use. We can pass an optimizer instance (e.g., `tf.keras.optimizers.Adam`, `tf.keras.optimizers.RMSProp`), which are defined in  `tf.train` module.\n",
        "* `loss`: The function to minimize during optimization. Common choices include `mean square error (mse)`, `[categorical|binary]_crossentropy`. Loss functions are specified by name or by passing a callable object from the `tf.keras.losses` module.\n",
        "* `metrics`: Used to monitor training. We can put string names or callables defined in `tf.keras.metrics` module (e.g. `'accuracy'`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cBrLLCDpq2a"
      },
      "source": [
        "# Choose loss function and optimizer for training\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy() # kreas에서 제공하는 cross entropy\n",
        "optimizer = tf.keras.optimizers.Adam() # Adam optimizer\n",
        "\n",
        "# Metrics to measure loss and accuracy of the model\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXKIy_UECa7P"
      },
      "source": [
        "### Train and Test functions using `tf.function`\n",
        "By annotating a train function with `tf.function`, TensorFlow internally creates a graph so that it can benefit from graph-based execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUZYje1bC1xB"
      },
      "source": [
        "# Define function for training\n",
        "@tf.function # Decorater 문법\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images, training=True) # forward\n",
        "    loss = loss_fn(labels, predictions) # loss fn\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "\n",
        "# Define function for testing\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images, training=False)\n",
        "  loss = loss_fn(labels, predictions)\n",
        "\n",
        "  test_loss(loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDilJK1dC4f_"
      },
      "source": [
        "### Prepare the dataset and start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "797JZG-zDBFa",
        "outputId": "8ef3c986-86b6-40b1-b9ab-9203f97d251e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "# Prepare the dataset using tf.data\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_ds = train_ds.shuffle(10000)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_ds = test_ds.batch(batch_size)\n",
        "\n",
        "\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Reset the metrics at each epoch\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "    for images, labels in train_ds:\n",
        "      train_step(images, labels)\n",
        "\n",
        "    for images, labels in test_ds:\n",
        "      test_step(images, labels)\n",
        "\n",
        "    print('Epoch: %02d' % (epoch + 1),\n",
        "          'Loss = {:2.4f}'.format(train_loss.result()),\n",
        "          'Train accuracy = {:2.4f}'.format(train_accuracy.result()),\n",
        "          'Test loss = {:2.4f}'.format(test_loss.result()),\n",
        "          'Test accuracy = {:2.4f}'.format(test_accuracy.result()))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 Loss = 0.2950 Train accuracy = 0.9108 Test loss = 0.0809 Test accuracy = 0.9760\n",
            "Epoch: 02 Loss = 0.0862 Train accuracy = 0.9735 Test loss = 0.0587 Test accuracy = 0.9822\n",
            "Epoch: 03 Loss = 0.0618 Train accuracy = 0.9808 Test loss = 0.0487 Test accuracy = 0.9860\n",
            "Epoch: 04 Loss = 0.0486 Train accuracy = 0.9850 Test loss = 0.0433 Test accuracy = 0.9868\n",
            "Epoch: 05 Loss = 0.0372 Train accuracy = 0.9887 Test loss = 0.0447 Test accuracy = 0.9857\n",
            "Epoch: 06 Loss = 0.0313 Train accuracy = 0.9904 Test loss = 0.0455 Test accuracy = 0.9869\n",
            "Epoch: 07 Loss = 0.0278 Train accuracy = 0.9914 Test loss = 0.0473 Test accuracy = 0.9851\n",
            "Epoch: 08 Loss = 0.0217 Train accuracy = 0.9935 Test loss = 0.0434 Test accuracy = 0.9871\n",
            "Epoch: 09 Loss = 0.0182 Train accuracy = 0.9942 Test loss = 0.0450 Test accuracy = 0.9879\n",
            "Epoch: 10 Loss = 0.0166 Train accuracy = 0.9944 Test loss = 0.0516 Test accuracy = 0.9870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7f9KSx3D9kF"
      },
      "source": [
        "## More simplified process using Keras API\n",
        "Keras API provides much simpler version to define a model and train a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvCIHyMGEPEo"
      },
      "source": [
        "### Defining a model\n",
        "Let's take a look how we can define a model using Keras API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8PUmEq5rO44"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# Let's build a stack of *sequential* layers, which is\n",
        "# the most common form of neural network graphs.\n",
        "model = models.Sequential()\n",
        "\n",
        "# Adds a reshaping layer that transforms (28, 28, 1) to (784,)\n",
        "model.add(layers.Reshape((784,), input_shape=(28, 28, 1)))\n",
        "\n",
        "# Adds a dense layer with 128 units to the model\n",
        "model.add(layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "# Adds another layer, which has L2 regularization applied to the kernel matrix\n",
        "model.add(layers.Dense(units=64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "\n",
        "# Adds a dense layer with 10 output units\n",
        "model.add(layers.Dense(units=10, activation='linear'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJq7I5kOc1H-"
      },
      "source": [
        "### Setting up training\n",
        "After the model is constructed, `compile` method configures how to learn the model, by specifying optimizer, loss function and metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocskyx96c0UY"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), #activation이 softmax일 경우 from_logits가 false여야 한다.\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSo7qrwZlOrl"
      },
      "source": [
        "### Training a model\n",
        "We can train the model using the `fit` method and then the model is \"fit\" to the training data. We can specify the training data to use (`images_train` and `labels_train`), how many epochs we will run (`epochs`), and how many items to be processed in a batch (`batch_size`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPOV-4VXk53s",
        "outputId": "34acbb19-ee65-4ee3-d3ac-18d1b1324b45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10, batch_size=128)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.6713 - accuracy: 0.9021\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2717 - accuracy: 0.9490\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1928 - accuracy: 0.9608\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1568 - accuracy: 0.9675\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1356 - accuracy: 0.9723\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1211 - accuracy: 0.9745\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1088 - accuracy: 0.9772\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0999 - accuracy: 0.9802\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0928 - accuracy: 0.9816\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0871 - accuracy: 0.9825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff3212040f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymPOEP3BlivE"
      },
      "source": [
        "### Evaluating the model\n",
        "Finally, we evaluate the trained model using test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV5w-V99l0Di",
        "outputId": "7129a706-19f0-4909-b90c-ccb85895f5f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.1084 - accuracy: 0.9740\n",
            "Test accuracy: 0.9739999771118164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4ORwtammNNb"
      },
      "source": [
        "### **Quiz**\n",
        "First, define a multi-layer model using Keras API following the CNN model defined in the beginning.\n",
        "\n",
        "The model comprises 3 convolutional layers, 3 max pooling layers, and 1 dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhKpYAgszdkI"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "############# Write here. #############\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3), activation = 'relu', padding='valid'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Conv2D(64,(3,3), activation = 'relu', padding='valid'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Conv2D(128,(3,3), activation = 'relu', padding='valid'))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "#######################################"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnL8eeL613b"
      },
      "source": [
        "Using the model and `(train_images, train_labels)` above, let's train the model using the following configuration:\n",
        "* optimizer: `tf.keras.optimizers.Adam`\n",
        "* learning rate: 0.001\n",
        "* loss: `SparseCategoricalCrossentropy`\n",
        "* metrics: `accuracy`\n",
        "* batch size: 128\n",
        "* epochs: 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0tNzWLWz0bj",
        "outputId": "09a2f3b8-0ada-4905-e625-ce7e604b452c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# train accuracy 최소한 95%는 나와야 한다.\n",
        "############# Write here. #############\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=128)\n",
        "#######################################\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2802 - accuracy: 0.9153\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0816 - accuracy: 0.9754\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0580 - accuracy: 0.9820\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0460 - accuracy: 0.9861\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0383 - accuracy: 0.9879\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0300 - accuracy: 0.9905\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0260 - accuracy: 0.9916\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0225 - accuracy: 0.9926\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0192 - accuracy: 0.9935\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0163 - accuracy: 0.9945\n",
            "313/313 - 1s - loss: 0.0494 - accuracy: 0.9871\n",
            "Test accuracy: 0.9871000051498413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOowIsLDs7J_"
      },
      "source": [
        "## Wrap-up\n",
        "\n",
        "So far, we have learned how we can define and train models in TensorFlow. For more information you can refer to [guides in TensorFlow official website](https://www.tensorflow.org/guide) and many other blog posts."
      ]
    }
  ]
}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TF_high_level_apis.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UwlPAA8ZJUsr"},"source":["Copyright (C) 2019 Software Platform Lab, Seoul National University\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\"); \n","\n","you may not use this file except in compliance with the License. \n","\n","You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 \n","\n","Unless required by applicable law or agreed to in writing, software \n","\n","distributed under the License is distributed on an \"AS IS\" BASIS, \n","\n","\n","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n","\n","\n","See the License for the specific language governing permissions and\n","\n","\n","limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"sO8dQBJs5Yxh"},"source":["## Defining a model in TensorFlow \n"]},{"cell_type":"markdown","metadata":{"id":"ZV9KmwLR_wBQ"},"source":["In TensorFlow, various libraries regarding the model definition are provided under `tf.keras`."]},{"cell_type":"markdown","metadata":{"id":"JqWzzFUO79nx"},"source":["### Model Subclassing\n","We can build a fully-customizable model by subclassing [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model) and defining your own forward pass. Layers are created in the `__init__` method, provided by the [tf.keras.layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers)  and they are set as attributes of the class instance. The forward pass is defined in the `call` method. You can access model variables by `model.trainable_variables`.\n","\n","Below is an example of a linear regression model to be defined as a subclass of `tf.keras.Model`, and then be trained using loss function, gradient function and optimizer provided in [tf.keras.optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). Useful loss functions are also provided in [tf.keras.losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses). We will cover these in more detail as we go on."]},{"cell_type":"code","metadata":{"id":"zu-X05yCDq9V"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aRHEy317_-s0"},"source":["NUM_EXAMPLES = 2000\n","toy_inputs = tf.random.normal([NUM_EXAMPLES, 1])\n","noise = tf.random.normal([NUM_EXAMPLES, 1])\n","toy_outputs = toy_inputs * 2 - 1 + noise * 1/4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uy1x6VF-_-s1","executionInfo":{"status":"ok","timestamp":1605255204858,"user_tz":-540,"elapsed":4034,"user":{"displayName":"강민수","photoUrl":"","userId":"02601739229520810364"}},"outputId":"2fb4909a-e983-4e94-9aa6-d9bd7c918eb8","colab":{"base_uri":"https://localhost:8080/"}},"source":["class ToyModel(tf.keras.Model):\n","    def __init__(self):\n","        \"\"\"Define layers\"\"\"\n","        super(ToyModel, self).__init__()\n","        self.dense = tf.keras.layers.Dense(units=1)\n","\n","    def call(self, input):\n","        \"\"\"Define forward pass.\"\"\"\n","        result = self.dense(input)        \n","        return result\n","\n","\n","# The loss function to be optimized (MSE loss) mean squared error\n","def loss(model, inputs, targets):\n","    error = model(inputs) - targets\n","    return tf.reduce_mean(tf.square(error))\n","\n","optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n","\n","model = ToyModel()\n","print(\"Initial loss: {:.3f}\".format(loss(model, toy_inputs, toy_outputs)))\n","print(\"Trainable variables:\")\n","for var in model.trainable_variables:\n","  print(\"\\t\", var.name, \": \", var.numpy())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Initial loss: 6.849\n","Trainable variables:\n","\t toy_model/dense/kernel:0 :  [[-0.3977511]]\n","\t toy_model/dense/bias:0 :  [0.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QZ3w_EmG7shn","executionInfo":{"status":"ok","timestamp":1605255204859,"user_tz":-540,"elapsed":4026,"user":{"displayName":"강민수","photoUrl":"","userId":"02601739229520810364"}},"outputId":"b0ad466c-774d-4985-bf30-da30b55ae750","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Training loop\n","\n","for i in range(300):\n","    with tf.GradientTape() as tape: # GradientTape는 pytorch에서 autoGrad와 비슷. gradient를 사용하고 싶을 때 사용\n","    # pytorch의 경우 with no grad로 gradient를 사용 안할 때 적어줘야함.\n","        loss_value = loss(model, toy_inputs, toy_outputs)\n","    grads = tape.gradient(loss_value, model.trainable_variables)\n","    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","    if i % 20 == 0:\n","        print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, toy_inputs, toy_outputs)))\n","\n","print(\"Final loss: {:.3f}\".format(loss(model, toy_inputs, toy_outputs)))\n","print(\"Trainable variables:\")\n","for var in model.trainable_variables:\n","  print(\"\\t\", var.name, \": \", var.numpy()) # 우리가 원한 2x - 1 을 잘 train한 것을 볼 수 있다."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loss at step 000: 6.577\n","Loss at step 020: 2.938\n","Loss at step 040: 1.332\n","Loss at step 060: 0.624\n","Loss at step 080: 0.311\n","Loss at step 100: 0.173\n","Loss at step 120: 0.112\n","Loss at step 140: 0.085\n","Loss at step 160: 0.073\n","Loss at step 180: 0.068\n","Loss at step 200: 0.066\n","Loss at step 220: 0.064\n","Loss at step 240: 0.064\n","Loss at step 260: 0.064\n","Loss at step 280: 0.064\n","Final loss: 0.064\n","Trainable variables:\n","\t toy_model/dense/kernel:0 :  [[1.9924881]]\n","\t toy_model/dense/bias:0 :  [-0.9811844]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I8MEnHhAvskB"},"source":["It's not required to set an input shape for the `tf.keras.Model` class since the parameters are set the first time input is passed to the layer.\n","\n","tf.keras.layers classes create and contain their own model variables that are tied to the lifetime of their layer objects. To share layer variables, share their objects.\n","\n","Below examples shows a new model that relies on the previous toy model. We are going to employ an additional bias to fit a slightly different data."]},{"cell_type":"code","metadata":{"id":"eFF5jQ___-s7","executionInfo":{"status":"ok","timestamp":1605255204861,"user_tz":-540,"elapsed":4022,"user":{"displayName":"강민수","photoUrl":"","userId":"02601739229520810364"}},"outputId":"ac721854-8c0b-483c-bc61-7275758d5367","colab":{"base_uri":"https://localhost:8080/"}},"source":["toy_outputs_2 = toy_outputs + 3\n","\n","class ToyModel2(tf.keras.Model):\n","    def __init__(self, toy_model):\n","        \"\"\"Define layers\"\"\"\n","        super(ToyModel2, self).__init__()\n","        self.toy_model = toy_model\n","        self.b = tf.Variable(0., name='another_bias')\n","\n","    def call(self, input):\n","        \"\"\"Define forward pass.\"\"\"\n","        result = self.toy_model(input)        \n","        return result + self.b\n","\n","\n","model2 = ToyModel2(model)\n","print(\"Initial loss: {:.3f}\".format(loss(model2, toy_inputs, toy_outputs_2)))\n","print(\"Trainable variables:\")\n","for var in model2.trainable_variables:\n","  print(\"\\t\", var.name, \": \", var.numpy())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Initial loss: 9.047\n","Trainable variables:\n","\t toy_model/dense/kernel:0 :  [[1.9924881]]\n","\t toy_model/dense/bias:0 :  [-0.9811844]\n","\t another_bias:0 :  0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xZf0cTk7_-s9"},"source":["We are only optimizing the additional bias. The weight and bias of toy_model_1 does not change."]},{"cell_type":"code","metadata":{"id":"PhNlE5mTw7bX","executionInfo":{"status":"ok","timestamp":1605255205719,"user_tz":-540,"elapsed":4874,"user":{"displayName":"강민수","photoUrl":"","userId":"02601739229520810364"}},"outputId":"1f7de75b-da64-401c-e484-1c952e863757","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Training loop\n","for i in range(300):\n","    with tf.GradientTape() as tape: # gradient를 추가한다.\n","        loss_value = loss(model2, toy_inputs, toy_outputs_2)\n","    grads = tape.gradient(loss_value, [model2.b]) # gradient w.r.t. `model2.b`, not `model2.trainable_variables`\n","    optimizer.apply_gradients(zip(grads, [model2.b]))# optimize only `model2.b`\n","    if i % 20 == 0:\n","        print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model2, toy_inputs, toy_outputs_2)))\n","\n","print(\"Final loss: {:.3f}\".format(loss(model2, toy_inputs, toy_outputs_2)))\n","print(\"Trainable variables:\")\n","for var in model2.trainable_variables:\n","  print(\"\\t\", var.name, \": \", var.numpy()) # another bias가 잘 학습되었다.\n","  # model2의 graident를 확인해서 update하였기 때문에 기존 model의 variable은 변하지 않는다."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loss at step 000: 8.691\n","Loss at step 020: 3.909\n","Loss at step 040: 1.778\n","Loss at step 060: 0.828\n","Loss at step 080: 0.404\n","Loss at step 100: 0.215\n","Loss at step 120: 0.131\n","Loss at step 140: 0.094\n","Loss at step 160: 0.077\n","Loss at step 180: 0.070\n","Loss at step 200: 0.066\n","Loss at step 220: 0.065\n","Loss at step 240: 0.064\n","Loss at step 260: 0.064\n","Loss at step 280: 0.064\n","Final loss: 0.064\n","Trainable variables:\n","\t toy_model/dense/kernel:0 :  [[1.9924881]]\n","\t toy_model/dense/bias:0 :  [-0.9811844]\n","\t another_bias:0 :  2.9902594\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bjAodT-v_-r7"},"source":["## Convolutional Neural Networks\n","Build simple CNN in TensorFlow.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2LQHVwI1g_PF"},"source":["### Preparing MNIST Dataset"]},{"cell_type":"code","metadata":{"id":"LydTwAzMhHw0","executionInfo":{"status":"ok","timestamp":1605255206687,"user_tz":-540,"elapsed":5836,"user":{"displayName":"강민수","photoUrl":"","userId":"02601739229520810364"}},"outputId":"6f89b63f-a9ca-45a4-87c1-42042bfd9a25","colab":{"base_uri":"https://localhost:8080/"}},"source":["import tensorflow as tf\n","\n","# Download the mnist dataset using keras\n","data_train, data_test = tf.keras.datasets.mnist.load_data()\n","\n","# Parse images and labels (unpack)\n","(train_images, train_labels) = data_train\n","(test_images, test_labels) = data_test\n","\n","# Numpy reshape & type casting\n","train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n","test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n","train_labels = train_labels.astype('int64')\n","test_labels = test_labels.astype('int64')\n","\n","\n","# Normalizing the images to the range of [0., 1.]\n","train_images /= 255.\n","test_images /= 255.\n","\n","print(train_images.shape, train_labels.shape)\n","print(test_images.shape, test_labels.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(60000, 28, 28, 1) (60000,)\n","(10000, 28, 28, 1) (10000,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tJ5XuFPCBOZR"},"source":["### Define the CNN Model"]},{"cell_type":"code","metadata":{"id":"i_USTku5_-r8"},"source":["from tensorflow.keras import Model\n","# Construct a tf.keras.model using tf.keras\n","class MyCNN(Model):\n","  def __init__(self):\n","    super(MyCNN, self).__init__()\n","    self.conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='valid')\n","    self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='valid')\n","    self.conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='valid')\n","    self.maxpool = tf.keras.layers.MaxPooling2D((2, 2))\n","    self.flatten = tf.keras.layers.Flatten()\n","    self.dense1 = tf.keras.layers.Dense(256, activation='relu')\n","    self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n","\n","  def call(self, x):\n","    x = self.conv1(x)\n","    x = self.maxpool(x)\n","\n","    x = self.conv2(x)\n","    x = self.maxpool(x)\n","\n","    x = self.conv3(x)\n","    x = self.maxpool(x)\n","\n","    x = self.flatten(x)\n","    x = self.dense1(x)\n","    x = self.dense2(x)\n","    \n","    return x\n","\n","# Create model\n","model = MyCNN()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yk4Cg8gRpWH_"},"source":["### Setting up training\n","After the model is constructed, we specify optimizer and loss function. We can also monitor training using metrics:\n","* `optimizer`: This field specifies which optimizer to use. We can pass an optimizer instance (e.g., `tf.keras.optimizers.Adam`, `tf.keras.optimizers.RMSProp`), which are defined in  `tf.train` module.\n","* `loss`: The function to minimize during optimization. Common choices include `mean square error (mse)`, `[categorical|binary]_crossentropy`. Loss functions are specified by name or by passing a callable object from the `tf.keras.losses` module.\n","* `metrics`: Used to monitor training. We can put string names or callables defined in `tf.keras.metrics` module (e.g. `'accuracy'`)"]},{"cell_type":"code","metadata":{"id":"6cBrLLCDpq2a"},"source":["# Choose loss function and optimizer for training\n","loss_fn = tf.keras.losses.SparseCategoricalCrossentropy() # kreas에서 제공하는 cross entropy\n","optimizer = tf.keras.optimizers.Adam() # Adam optimizer\n","\n","# Metrics to measure loss and accuracy of the model\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zXKIy_UECa7P"},"source":["### Train and Test functions using `tf.function`\n","By annotating a train function with `tf.function`, TensorFlow internally creates a graph so that it can benefit from graph-based execution."]},{"cell_type":"code","metadata":{"id":"KUZYje1bC1xB"},"source":["# Define function for training\n","@tf.function # Decorater 문법\n","def train_step(images, labels):\n","  with tf.GradientTape() as tape:\n","    predictions = model(images, training=True) # forward\n","    loss = loss_fn(labels, predictions) # loss fn\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  train_loss(loss)\n","  train_accuracy(labels, predictions)\n","\n","# Define function for testing\n","@tf.function\n","def test_step(images, labels):\n","  predictions = model(images, training=False)\n","  loss = loss_fn(labels, predictions)\n","\n","  test_loss(loss)\n","  test_accuracy(labels, predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CDilJK1dC4f_"},"source":["### Prepare the dataset and start training"]},{"cell_type":"code","metadata":{"id":"797JZG-zDBFa","executionInfo":{"status":"ok","timestamp":1605255225669,"user_tz":-540,"elapsed":24798,"user":{"displayName":"강민수","photoUrl":"","userId":"02601739229520810364"}},"outputId":"282dc506-80e5-4861-eb8c-b51dc828c0bb","colab":{"base_uri":"https://localhost:8080/"}},"source":["batch_size = 128\n","\n","# Prepare the dataset using tf.data\n","train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n","train_ds = train_ds.shuffle(10000)\n","train_ds = train_ds.batch(batch_size)\n","\n","test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n","test_ds = test_ds.batch(batch_size)\n","\n","\n","\n","EPOCHS = 10\n","\n","for epoch in range(EPOCHS):\n","    # Reset the metrics at each epoch\n","    train_loss.reset_states()\n","    train_accuracy.reset_states()\n","    test_loss.reset_states()\n","    test_accuracy.reset_states()\n","\n","    for images, labels in train_ds:\n","      train_step(images, labels)\n","\n","    for images, labels in test_ds:\n","      test_step(images, labels)\n","\n","    print('Epoch: %02d' % (epoch + 1),\n","          'Loss = {:2.4f}'.format(train_loss.result()),\n","          'Train accuracy = {:2.4f}'.format(train_accuracy.result()),\n","          'Test loss = {:2.4f}'.format(test_loss.result()),\n","          'Test accuracy = {:2.4f}'.format(test_accuracy.result()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 01 Loss = 0.2863 Train accuracy = 0.9145 Test loss = 0.0880 Test accuracy = 0.9738\n","Epoch: 02 Loss = 0.0860 Train accuracy = 0.9732 Test loss = 0.0617 Test accuracy = 0.9814\n","Epoch: 03 Loss = 0.0608 Train accuracy = 0.9815 Test loss = 0.0652 Test accuracy = 0.9792\n","Epoch: 04 Loss = 0.0465 Train accuracy = 0.9853 Test loss = 0.0544 Test accuracy = 0.9836\n","Epoch: 05 Loss = 0.0378 Train accuracy = 0.9880 Test loss = 0.0488 Test accuracy = 0.9863\n","Epoch: 06 Loss = 0.0330 Train accuracy = 0.9895 Test loss = 0.0421 Test accuracy = 0.9877\n","Epoch: 07 Loss = 0.0270 Train accuracy = 0.9917 Test loss = 0.0443 Test accuracy = 0.9875\n","Epoch: 08 Loss = 0.0242 Train accuracy = 0.9920 Test loss = 0.0556 Test accuracy = 0.9835\n","Epoch: 09 Loss = 0.0187 Train accuracy = 0.9940 Test loss = 0.0481 Test accuracy = 0.9875\n","Epoch: 10 Loss = 0.0170 Train accuracy = 0.9945 Test loss = 0.0548 Test accuracy = 0.9858\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K7f9KSx3D9kF"},"source":["## More simplified process using Keras API\n","Keras API provides much simpler version to define a model and train a model."]},{"cell_type":"markdown","metadata":{"id":"RvCIHyMGEPEo"},"source":["### Defining a model\n","Let's take a look how we can define a model using Keras API."]},{"cell_type":"code","metadata":{"id":"j8PUmEq5rO44"},"source":["import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","\n","# Let's build a stack of *sequential* layers, which is\n","# the most common form of neural network graphs.\n","model = models.Sequential()\n","\n","# Adds a reshaping layer that transforms (28, 28, 1) to (784,)\n","model.add(layers.Reshape((784,), input_shape=(28, 28, 1)))\n","\n","# Adds a dense layer with 128 units to the model\n","model.add(layers.Dense(units=128, activation='relu'))\n","\n","# Adds another layer, which has L2 regularization applied to the kernel matrix\n","model.add(layers.Dense(units=64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n","\n","# Adds a dense layer with 10 output units\n","model.add(layers.Dense(units=10, activation='linear'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nJq7I5kOc1H-"},"source":["### Setting up training\n","After the model is constructed, `compile` method configures how to learn the model, by specifying optimizer, loss function and metrics."]},{"cell_type":"code","metadata":{"id":"Ocskyx96c0UY"},"source":["model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), #activation이 softmax일 경우 from_logits가 false여야 한다.\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OSo7qrwZlOrl"},"source":["### Training a model\n","We can train the model using the `fit` method and then the model is \"fit\" to the training data. We can specify the training data to use (`images_train` and `labels_train`), how many epochs we will run (`epochs`), and how many items to be processed in a batch (`batch_size`)."]},{"cell_type":"code","metadata":{"id":"nPOV-4VXk53s","executionInfo":{"status":"ok","timestamp":1605255239690,"user_tz":-540,"elapsed":38806,"user":{"displayName":"강민수","photoUrl":"","userId":"02601739229520810364"}},"outputId":"d18d3141-cb8e-4a34-b514-334cb3492af7","colab":{"base_uri":"https://localhost:8080/"}},"source":["model.fit(train_images, train_labels, epochs=10, batch_size=128)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.6692 - accuracy: 0.9000\n","Epoch 2/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.2750 - accuracy: 0.9479\n","Epoch 3/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1970 - accuracy: 0.9588\n","Epoch 4/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9666\n","Epoch 5/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1393 - accuracy: 0.9711\n","Epoch 6/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1233 - accuracy: 0.9746\n","Epoch 7/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1126 - accuracy: 0.9765\n","Epoch 8/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1030 - accuracy: 0.9791\n","Epoch 9/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9806\n","Epoch 10/10\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9826\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f6270729390>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"ymPOEP3BlivE"},"source":["### Evaluating the model\n","Finally, we evaluate the trained model using test dataset."]},{"cell_type":"code","metadata":{"id":"yV5w-V99l0Di","executionInfo":{"status":"ok","timestamp":1605255240453,"user_tz":-540,"elapsed":39563,"user":{"displayName":"강민수","photoUrl":"","userId":"02601739229520810364"}},"outputId":"825cad8e-12cc-4ff0-fbc5-11caa4e30d7a","colab":{"base_uri":"https://localhost:8080/"}},"source":["test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n","\n","print('Test accuracy:', test_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["313/313 - 1s - loss: 0.1218 - accuracy: 0.9723\n","Test accuracy: 0.9722999930381775\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g4ORwtammNNb"},"source":["### **Quiz**\n","First, define a multi-layer model using Keras API following the CNN model defined in the beginning.\n","\n","The model comprises 3 convolutional layers, 3 max pooling layers, and 1 dense layer."]},{"cell_type":"code","metadata":{"id":"lhKpYAgszdkI","executionInfo":{"status":"error","timestamp":1605256866644,"user_tz":-540,"elapsed":741,"user":{"displayName":"강민수","photoUrl":"","userId":"02601739229520810364"}},"outputId":"64b71c4a-721a-472d-d39c-674d69f7e93b","colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["from tensorflow.keras import layers\n","\n","* optimizer: `tf.keras.optimizers.Adam`\n","* learning rate: 0.001\n","* loss: `SparseCategoricalCrossentropy`\n","* metrics: `accuracy`\n","* batch size: 128\n","* epochs: 10\n","\n","############# Write here. #############\n","model = models.Sequential()\n","model.add(layers.conv2D(32,(3,3), activation = 'relu'))\n","mdoel.add(layers.MaxPooling2D(2,2))\n","model.add(layers.conv2D(64,(3,3), activation = 'relu'))\n","mdoel.add(layers.MaxPooling2D(2,2))\n","model.add(layers.conv2D(128,(3,3), activation = 'relu'))\n","mdoel.add(layers.MaxPooling2D(2,2))\n","model.add(layers.Dense(256,activation='...'))\n","model.add(layers.Dense(128,activation='...'))\n","\n","#######################################"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-66623b2d02d6>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    * optimizer: `tf.keras.optimizers.Adam`\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","metadata":{"id":"lmnL8eeL613b"},"source":["Using the model and `(train_images, train_labels)` above, let's train the model using the following configuration:\n","* optimizer: `tf.keras.optimizers.Adam`\n","* learning rate: 0.001\n","* loss: `SparseCategoricalCrossentropy`\n","* metrics: `accuracy`\n","* batch size: 128\n","* epochs: 10"]},{"cell_type":"code","metadata":{"id":"B0tNzWLWz0bj","executionInfo":{"status":"error","timestamp":1605256866647,"user_tz":-540,"elapsed":734,"user":{"displayName":"강민수","photoUrl":"","userId":"02601739229520810364"}},"outputId":"d858ff41-0575-4bf3-f89a-93d9b529d71f","colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["# train accuracy 최소한 95%는 나와야 한다.\n","############# Write here. #############\n","model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","              metrics=['accuracy'])\n","\n","model.fit(train_images, train_labels, epochs=10, batch_size=128)\n","#######################################\n","\n","test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n","print('Test accuracy:', test_acc)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-4ef0edd41866>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","metadata":{"id":"XOowIsLDs7J_"},"source":["## Wrap-up\n","\n","So far, we have learned how we can define and train models in TensorFlow. For more information you can refer to [guides in TensorFlow official website](https://www.tensorflow.org/guide) and many other blog posts."]}]}